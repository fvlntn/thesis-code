{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suspended-harrison",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.utils import set_determinism\n",
    "import numpy as np\n",
    "\n",
    "from seg_data import getDataset\n",
    "from transforms_dict import getSegmentationPostProcessingForLabel, getSegmentationPostProcessingForLabelOutput\n",
    "from utils import compute_mean_dice, getReducePlateauScheduler, getAdamOptimizer, loadExistingModel\n",
    "from utils import print_model_output, check_model_name, getDevice\n",
    "\n",
    "from monai.transforms import Activations\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb288e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "modelname = \"test_seg_labels_unetr.pth\"\n",
    "dataset = \"painfactlabels\"\n",
    "ft = None\n",
    "ct = None\n",
    "batchsize = 1\n",
    "num_epochs = 200\n",
    "factor = 0.9\n",
    "patience = 10\n",
    "augment = True\n",
    "N4 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531ae899",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving to test_seg_labels_unetr.pth\n"
     ]
    }
   ],
   "source": [
    "#Modelname and device\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "modelname = check_model_name(modelname)\n",
    "print_model_output(modelname)\n",
    "set_determinism(seed=0)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "device = getDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d4bcd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#postprocessing\n",
    "outputs_processing = getSegmentationPostProcessingForLabelOutput()\n",
    "labels_processing = getSegmentationPostProcessingForLabel()\n",
    "\n",
    "#activations\n",
    "softmax = Activations(other=nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c15181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Using Painfact-Segmentation dataset.\n",
      "=> Using augmented transforms for train set\n"
     ]
    }
   ],
   "source": [
    "#dataloaders\n",
    "dataloaders, size = getDataset(dataset=dataset, batch=batchsize, augment=augment, training=True, n4=N4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5076fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUNETRForSegmentation():        \n",
    "    device = getDevice()              \n",
    "    model = monai.networks.nets.UNETR(\n",
    "        in_channels=1,\n",
    "        out_channels=4,\n",
    "        img_size=(96, 96, 96),\n",
    "        feature_size=16,\n",
    "        hidden_size=768,\n",
    "        mlp_dim=3072,\n",
    "        num_heads=16,\n",
    "        pos_embed=\"perceptron\",\n",
    "        norm_name=\"instance\",\n",
    "        res_block=True,\n",
    "        dropout_rate=0.0,           \n",
    "    ).to(device)                      \n",
    "    return model                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75fe9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metric MUNet\n",
    "def metric_munet(preds, labels):  \n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    preds = preds.detach().cpu().numpy()    \n",
    "    labels[np.where(labels == np.amax(labels, axis=0))] = 1\n",
    "    labels[labels != 1] = 0\n",
    "    dice=2*np.sum(labels*preds,(1,2,3))/(np.sum((labels+preds),(1,2,3))+1)    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b64c816",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Loss\n",
    "def loss_Dice(preds, labels):\n",
    "    dice = 1-torch.div(\n",
    "        torch.sum(torch.mul(torch.mul(labels,preds),2)),\n",
    "        torch.sum(torch.mul(preds,preds)) + torch.sum(torch.mul(labels,labels))\n",
    "        )    \n",
    "    return dice\n",
    "\n",
    "def loss_CE(input, target):\n",
    "        n_pred_ch, n_target_ch = input.shape[1], target.shape[1]\n",
    "        if n_pred_ch == n_target_ch:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        else:\n",
    "            target = torch.squeeze(target, dim=1)\n",
    "        target = target.long()        \n",
    "        device = getDevice()\n",
    "        weight = torch.FloatTensor([1.0, 5.0, 5.0, 20.0]).to(device)\n",
    "        return nn.CrossEntropyLoss(reduction=\"mean\", weight=weight)(input, target)\n",
    "\n",
    "loss_GDice = monai.losses.GeneralizedDiceLoss(other_act=nn.Softmax(dim=1))\n",
    "weight = torch.FloatTensor([1.0, 5.0, 5.0, 20.0]).to(device)\n",
    "loss_DiceCE = monai.losses.DiceCELoss(other_act=nn.Softmax(dim=1), ce_weight=weight)\n",
    "\n",
    "def loss_GDiceCE(input, target, lambda_gdice=1.0, lambda_ce=1.0):    \n",
    "    GDice = loss_GDice(input, target)\n",
    "    CE = loss_CE(input, target)    \n",
    "    GDiceCELoss = lambda_gdice*GDice + lambda_ce*CE\n",
    "    return GDiceCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7019bcdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/200\n",
      "train: loss: 1.6887, dice: 0.4217\n",
      "dices: 0.7852, 0.5406, 0.2750, 0.0861\n",
      "valid: loss: 1.7730, dice: 0.4367\n",
      "dices: 0.9000, 0.5248, 0.2542, 0.0678\n",
      "best loss 1.7730 at epoch 1\n",
      "----------\n",
      "epoch 2/200\n",
      "155/166\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train loop\n",
    "best_loss = np.inf\n",
    "writer = SummaryWriter()\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#Model optimizer and scheduler\n",
    "model = getUNETRForSegmentation()\n",
    "lr = 5e-4#/np.sqrt(6)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = getReducePlateauScheduler(optimizer, patience=patience, factor=factor)\n",
    "loadExistingModel(model, optimizer, ft, ct)\n",
    "\n",
    "train_dices = []\n",
    "valid_dices = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    for phase in ['train', 'valid']:\n",
    "        model.train()\n",
    "        \n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0        \n",
    "        metrics = []\n",
    "        for i in range(4):\n",
    "            metrics.append([])\n",
    "\n",
    "        for i, data in enumerate(dataloaders[phase]):\n",
    "            print(\"{}/{}\".format(\n",
    "                i, len(dataloaders[phase])), end='\\r'\n",
    "            )\n",
    "            optimizer.zero_grad()      \n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                inputs, labels = data[\"img\"].to(device), data[\"seg\"].to(device)\n",
    "                labels = labels.squeeze(2) \n",
    "                \n",
    "                if phase == 'train':        \n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    outputs = sliding_window_inference(inputs, (96, 96, 96), 4, model)                \n",
    "                loss = loss_GDiceCE(outputs, labels)\n",
    "                preds = [outputs_processing(pred) for pred in decollate_batch(outputs)]\n",
    "                labels = [labels_processing(label) for label in decollate_batch(labels)]  \n",
    "                for j in range(len(preds)):\n",
    "                    metric = metric_munet(preds[j], labels[j])                     \n",
    "                    for k in range(4):\n",
    "                        metrics[k].append(metric[k])                \n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= size[phase]\n",
    "        metrics_mean = [np.mean(x) for x in metrics]\n",
    "        running_metric = np.mean(metrics_mean)      \n",
    "\n",
    "        print(\n",
    "            \"{}: loss: {:.4f}, dice: {:.4f}\".format(\n",
    "                phase, running_loss, running_metric\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"dices: {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(\n",
    "                metrics_mean[0], metrics_mean[1], metrics_mean[2], metrics_mean[3]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if phase == 'train':\n",
    "            train_loss = running_loss               \n",
    "            train_dices.append(running_metric)\n",
    "        elif phase == 'valid':\n",
    "            valid_loss = running_loss \n",
    "            valid_dices.append(running_metric)\n",
    "            scheduler.step(running_loss)\n",
    "            if running_loss < best_loss:\n",
    "                best_loss = running_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict()\n",
    "                },\n",
    "                    './models/' + str(modelname))\n",
    "\n",
    "                print(\n",
    "                    \"best loss {:.4f} at epoch {}\".format(\n",
    "                        best_loss, best_epoch\n",
    "                    )\n",
    "                )            \n",
    "    writer.add_scalars('epoch_loss', {\n",
    "        'train': train_loss,\n",
    "        'valid': valid_loss,\n",
    "    }, epoch + 1)\n",
    "    \n",
    "\n",
    "print(f\"train completed\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in preds:\n",
    "    print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e842e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = outputs[0,:,64,64,64]\n",
    "print(x)\n",
    "x = preds[0][:,64,64,64]\n",
    "print(x)\n",
    "x = labels[0][:,64,64,64]\n",
    "print(x)\n",
    "print(outputs.shape)\n",
    "print(preds.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1887823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train Mean Dice\")\n",
    "x = [(i + 1) for i in range(len(train_dices))]\n",
    "y = train_dices\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [(i + 1) for i in range(len(valid_dices))]\n",
    "y = valid_dices\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import os\n",
    "labels = sorted(glob(os.path.join('dataset', 'Painfact-Segmentation', 'Label', \"*.nii.gz\")))\n",
    "weights_a = []\n",
    "weights_b = []\n",
    "weights_c = []\n",
    "weights_d = []\n",
    "for i in range(len(labels)):\n",
    "    print(i, end='\\r')\n",
    "    label = nib.load(labels[i]).get_fdata()\n",
    "    a = np.where(label == 0)[0].shape[0]\n",
    "    b = np.where(label == 1)[0].shape[0]\n",
    "    c = np.where(label == 2)[0].shape[0]\n",
    "    d = np.where(label == 3)[0].shape[0]\n",
    "    e = 305*216*227\n",
    "    weight_a = (1/a) * e/4\n",
    "    weight_b = (1/b) * e/4\n",
    "    weight_c = (1/c) * e/4\n",
    "    weight_d = (1/d) * e/4    \n",
    "    weights_a.append(weight_a)\n",
    "    weights_b.append(weight_b)\n",
    "    weights_c.append(weight_c)\n",
    "    weights_d.append(weight_d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(weights_a)/np.mean(weights_a))\n",
    "print(np.mean(weights_b)/np.mean(weights_a))\n",
    "print(np.mean(weights_c)/np.mean(weights_a))\n",
    "print(np.mean(weights_d)/np.mean(weights_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81139b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "mris = sorted(glob(os.path.join(\"dataset\", \"Painfact-Segmentation\", 'MRI', \"*.nii.gz\")))\n",
    "masks = sorted(glob(os.path.join(\"dataset\", \"Painfact-Segmentation\", 'Label', \"*.nii.gz\")))\n",
    "mri = mris[0]\n",
    "mask = masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bed85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Activations, ScaleIntensity, EnsureType, LoadImage\n",
    "from monai.transforms import Compose, AddChannel, Resize, RandRotate90d, Orientationd, Spacingd, CropForegroundd, RandCropByPosNegLabeld\n",
    "from monai.transforms import LoadImaged, AddChanneld, ScaleIntensityd, RandAffined, EnsureTyped, RandShiftIntensityd\n",
    "from monai.transforms import RandRotated, Resized, SqueezeDimd, ToTensord\n",
    "\n",
    "from transforms import CropMRId, BinaryMask, GetLargestComponent, GetLabelsAsOneHotd, Shaped, GetMaxChannelWise\n",
    "from transforms import N4MRI, LoadNibabel, NibabelToNumpy, ResampleMRIToAtlas, ToNibabel, SaveNibabel, InverseOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            minv=0.0, \n",
    "            maxv=1.0,\n",
    "        ),        \n",
    "        CropForegroundd(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            source_key=\"label\",\n",
    "            margin=5,\n",
    "        ),    \n",
    "        Shaped(keys=[\"image\"]),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=1,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),           \n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.5,\n",
    "            max_k=3,\n",
    "            spatial_axes=(0, 1),\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.5,\n",
    "            max_k=3,\n",
    "            spatial_axes=(1, 2),\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.5,\n",
    "            max_k=3,\n",
    "            spatial_axes=(2, 0),\n",
    "        ),\n",
    "        RandRotated(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            range_x=np.pi/4,\n",
    "            range_y=np.pi/4,\n",
    "            range_z=np.pi/4,\n",
    "            prob=0.25,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),   \n",
    "        GetLabelsAsOneHotd(\n",
    "                keys=[\"label\"],\n",
    "                get=True,\n",
    "                skip=False,\n",
    "            ),\n",
    "        EnsureTyped(\n",
    "                keys=[\"image\", \"label\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mris)):\n",
    "    print(\"{}/{}\".format(\n",
    "        i, len(mris)), end='\\r'\n",
    "    )\n",
    "    mdr = {'image': mris[i], 'label': masks[i]}\n",
    "    mdr2 = train_transforms(mdr)\n",
    "    print('-'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
