{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNjovRZAFEzf"
   },
   "source": [
    "# Paired Lung CT 3d registration with MONAI\n",
    "\n",
    "This tutorial shows how to use MONAI to register CT images acquired at different time points for a single patient. The images being registered are taken at inspiration and expiration for each subject. This is an intra subject registration. This type of intra subject registration is useful when there is a need to track certain features on a medical image such as tumor location when conducting invasive procedures.\n",
    "\n",
    "The usage of the following features are illustrated in this tutorial:\n",
    "1. Load Nifti image with metadata\n",
    "1. Transforms for dictionary format data\n",
    "1. Build LocalNet\n",
    "1. Warp an image with given dense displacement field (DDF) with Warp block\n",
    "1. Compute DiceLoss and BendingEnergyLoss\n",
    "1. Compute MeanDice metric\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_registration/paired_lung_ct.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kGLibY0FEzj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvM3K-VQFEzk"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOX-6zKMFEzl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5X_qzMcFEzl",
    "outputId": "571d6c35-dc5e-4ac5-85ee-8da234ed4526",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from monai.apps import download_url, download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.losses import BendingEnergyLoss, MultiScaleLoss, DiceLoss, LocalNormalizedCrossCorrelationLoss\n",
    "from monai.metrics import compute_meandice, DiceMetric\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.nets import GlobalNet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandAffined,\n",
    "    Resized,\n",
    "    ScaleIntensityd,\n",
    "    ToTensord,\n",
    "    SqueezeDimd,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    ")\n",
    "from monai.utils import set_determinism, first\n",
    "from glob import glob\n",
    "import itertools\n",
    "\n",
    "    \n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lm8P0aewFEzp"
   },
   "source": [
    "## Set dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bup-horBFEzp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"datasets2\", \"IRIS\")\n",
    "mris = sorted(glob(os.path.join(data_dir, 'MRI_N4_Resample_Norm', \"*.nii.gz\")))\n",
    "labels = sorted(glob(os.path.join(data_dir, 'Mask_Resample', \"*.nii.gz\")))\n",
    "mri_number = 4\n",
    "train_mris = mris[:mri_number]\n",
    "val_mris = mris[mri_number:mri_number+2]\n",
    "train_labels = labels[:mri_number]\n",
    "val_labels = labels[mri_number:mri_number+2]\n",
    "\n",
    "train_files = [\n",
    "    {\n",
    "        \"fixed_image\": train_mris[i],  \n",
    "        \"fixed_label\": train_labels[i],\n",
    "        \n",
    "        \"moving_image\": train_mris[j],\n",
    "        \"moving_label\": train_labels[j],\n",
    "    }    \n",
    "    for i, j in itertools.product(range(len(train_mris)), range(len(train_mris)))\n",
    "]\n",
    "\n",
    "val_files = [\n",
    "    {\n",
    "        \"fixed_image\": val_mris[i],                                    \n",
    "        \"moving_image\": val_mris[j],\n",
    "        \"fixed_label\": val_labels[i],\n",
    "        \"moving_label\": val_labels[j],\n",
    "    }    \n",
    "    for i, j in itertools.product(range(len(val_mris)), range(len(val_mris)))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF-VsWnLFEzp"
   },
   "source": [
    "## Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2iYIqSNFEzq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PsRCECnFEzq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),            \n",
    "        AddChanneld(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),   \n",
    "        ScaleIntensityd(\n",
    "            keys=[\"moving_image\", \"fixed_image\"],\n",
    "            minv=0.0, maxv=1.0,\n",
    "        ),\n",
    "        RandAffined(           \n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"],\n",
    "            mode=('bilinear', 'nearest', 'bilinear', 'nearest'),\n",
    "            prob=1.0,\n",
    "            rotate_range=(0, 0, np.pi / 15),             \n",
    "            scale_range=(0.1, 0.1, 0.1),\n",
    "        ),\n",
    "        EnsureTyped(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),          \n",
    "        AddChanneld(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),\n",
    "        ScaleIntensityd(\n",
    "            keys=[\"moving_image\", \"fixed_image\"],\n",
    "            minv=0.0, maxv=1.0,\n",
    "        ), \n",
    "        EnsureTyped(\n",
    "            keys=[\"moving_image\", \"moving_label\", \"fixed_image\", \"fixed_label\"]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIeQoki8FEzr"
   },
   "source": [
    "## Check transforms in DataLoader\n",
    "Visualize a single batch to check the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "FejZ4_hMFEzr",
    "lines_to_next_cell": 2,
    "outputId": "43f19e87-aac7-4581-eb50-235364e8b07b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "fixed_image = check_data[\"fixed_image\"][0][0]\n",
    "fixed_label = check_data[\"fixed_label\"][0][0]\n",
    "moving_image = check_data[\"moving_image\"][0][0]\n",
    "moving_label = check_data[\"moving_label\"][0][0]\n",
    "\n",
    "\n",
    "print(f\"moving_image shape: {moving_image.shape}, \"\n",
    "      f\"moving_label shape: {moving_label.shape}\")\n",
    "print(f\"fixed_image shape: {fixed_image.shape}, \"\n",
    "      f\"fixed_label shape: {fixed_label.shape}\")\n",
    "\n",
    "\n",
    "slice = 40\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"moving_image\")\n",
    "plt.imshow(moving_image[:, :, slice], cmap=\"gray\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"moving_label\")\n",
    "plt.imshow(moving_label[:, :, slice])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"fixed_image\")\n",
    "plt.imshow(fixed_image[:, :, slice], cmap=\"gray\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"fixed_label\")\n",
    "plt.imshow(fixed_label[:, :, slice])\n",
    "\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "print(np.min(moving_image.numpy()))\n",
    "print(np.max(moving_image.numpy()))\n",
    "print(np.min(moving_label.numpy()))\n",
    "print(np.max(moving_label.numpy()))\n",
    "print(np.min(fixed_image.numpy()))\n",
    "print(np.max(fixed_image.numpy()))\n",
    "print(np.min(fixed_label.numpy()))\n",
    "print(np.max(fixed_label.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdVVnsVWFEzs",
    "lines_to_next_cell": 2,
    "outputId": "23af569d-c529-4565-f347-56ca8e2e2556",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euJsnU8xFEzt"
   },
   "source": [
    "#### Create Model, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbWWMX5EFEzu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#def forward(batch_data, model):\n",
    "#    fixed_image = batch_data[\"fixed_image\"].to(device)\n",
    "#    moving_image = batch_data[\"moving_image\"].to(device)\n",
    "#    \n",
    "#    # predict DDF through GlobalNet\n",
    "#    ddf = model(torch.cat((moving_image, fixed_image), dim=1))\n",
    "#\n",
    "#    # warp moving image and label with the predicted ddf\n",
    "#    pred_image = warp_layer(moving_image, ddf)\n",
    "#\n",
    "#    return ddf, pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5rbHRWEFEzv",
    "outputId": "4189e08b-454b-4828-8f98-05f9fd1ddfe0",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#max_epochs = 3\n",
    "#val_interval = 1\n",
    "#epoch_loss_values = []\n",
    "#\n",
    "#for epoch in range(max_epochs):\n",
    "#    if (epoch + 1) % val_interval == 0 or epoch == 0:\n",
    "#        model.eval()\n",
    "#        with torch.no_grad():\n",
    "#            for val_data in val_loader:\n",
    "#\n",
    "#                val_ddf, val_pred_image = forward(val_data, model)\n",
    "#                val_fixed_image = val_data[\"fixed_image\"].to(device)\n",
    "#\n",
    "#    print(\"-\" * 10)\n",
    "#    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "#    model.train()\n",
    "#    epoch_loss = 0\n",
    "#    step = 0\n",
    "#    for batch_data in train_loader:\n",
    "#        step += 1\n",
    "#        optimizer.zero_grad()\n",
    "#\n",
    "#        ddf, pred_image = forward(batch_data, model)\n",
    "#        fixed_image = batch_data[\"fixed_image\"].to(device)\n",
    "#        \n",
    "#        loss = image_loss(pred_image, fixed_image)\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#        epoch_loss += loss.item()\n",
    "#\n",
    "#    epoch_loss /= step\n",
    "#    epoch_loss_values.append(epoch_loss)\n",
    "#    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC1KJwydFEzt",
    "outputId": "fe36fabe-0742-4e09-d3a4-5609cfb5fb69",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = GlobalNet(\n",
    "    image_size=(128, 128, 128),\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    num_channel_initial=16,\n",
    "    depth=5).to(device)\n",
    "warp_layer = Warp(\"bilinear\", \"border\").to(device)\n",
    "image_loss = LocalNormalizedCrossCorrelationLoss()\n",
    "label_loss = DiceLoss()\n",
    "label_loss = MultiScaleLoss(label_loss, scales=[0, 1, 2, 4, 8, 16])\n",
    "regularization = BendingEnergyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 3\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_loss = 100000\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    \n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    train_metric = 0\n",
    "    valid_metric = 0\n",
    "    train_lbl_loss = 0\n",
    "    valid_lbl_loss = 0\n",
    "    train_ddf_loss = 0\n",
    "    valid_ddf_loss = 0\n",
    "    train_img_loss = 0\n",
    "    valid_img_loss = 0\n",
    "        \n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()       \n",
    "            loader = train_loader\n",
    "        if phase == 'valid':\n",
    "            model.eval()         \n",
    "            loader = val_loader\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        running_metric = 0.0\n",
    "        running_img_loss = 0.0\n",
    "        running_lbl_loss = 0.0\n",
    "        running_ddf_loss = 0.0\n",
    "        \n",
    "    \n",
    "        for i, data in enumerate(loader):\n",
    "            print(i, end='\\r')\n",
    "                \n",
    "            optimizer.zero_grad()      \n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):                \n",
    "                \n",
    "                fixed_image = data[\"fixed_image\"].to(device) \n",
    "                #fixed_label = data[\"fixed_label\"].to(device) \n",
    "                moving_image = data[\"moving_image\"].to(device)\n",
    "                #moving_label = data[\"moving_label\"].to(device)\n",
    "\n",
    "                ddf = model(torch.cat((moving_image, fixed_image), dim=1))\n",
    "                \n",
    "                pred_image = warp_layer(moving_image, ddf)     \n",
    "                #pred_label = warp_layer(moving_label, ddf)\n",
    "                               \n",
    "                img_loss = 1 * image_loss(pred_image, fixed_image)\n",
    "                #lbl_loss = 20 * label_loss(pred_label, fixed_label)\n",
    "                ddf_loss = 10 * regularization(ddf)\n",
    "                loss = img_loss + ddf_loss\n",
    "                \n",
    "                if phase == 'train':                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            running_img_loss += img_loss.item()\n",
    "            running_ddf_loss += ddf_loss.item()\n",
    "            \n",
    "        \n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        epoch_img_loss = running_img_loss / len(loader)  \n",
    "        epoch_ddf_loss = running_ddf_loss / len(loader)     \n",
    "        \n",
    "        if phase == 'train':\n",
    "            train_loss = epoch_loss\n",
    "            train_img_loss = epoch_img_loss\n",
    "            train_ddf_loss = epoch_ddf_loss\n",
    "        elif phase == 'valid':\n",
    "            valid_loss = epoch_loss\n",
    "            valid_img_loss = epoch_img_loss\n",
    "            valid_ddf_loss = epoch_ddf_loss\n",
    "\n",
    "        print(\n",
    "            \"{}: loss: {:.4f} -- img: {:.4f}, ddf: {:.4f}\".format(\n",
    "                phase, epoch_loss, epoch_img_loss, epoch_ddf_loss,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if phase == 'valid':\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    },\n",
    "                    './models/registration/' + str('test_registration_resample.pth')\n",
    "                )\n",
    "                print(\n",
    "                    \"best loss {:.4f} at epoch {}\".format(\n",
    "                        best_loss, best_epoch\n",
    "                    )\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A2kp7EJEFEz0",
    "outputId": "b151fba3-c184-4a5e-a1be-87cc5d69d3ec",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "depth = 5 * 10\n",
    "plt.figure(\"check\", (18, 6))        \n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(f\"moving_image\")\n",
    "plt.imshow(moving_image.cpu().numpy()[0, 0, :, :, depth])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(f\"fixed_image\")\n",
    "plt.imshow(fixed_image.cpu().numpy()[0, 0, :, :, depth])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"pred_image\")\n",
    "plt.imshow(pred_image.cpu().numpy()[0, 0, :, :, depth])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of paired_lung_ct.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
