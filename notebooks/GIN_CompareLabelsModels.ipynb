{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "300883df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.utils import set_determinism\n",
    "import numpy as np\n",
    "\n",
    "from seg_data import getSegmentationDataset\n",
    "from seg_model import getUNetForSegmentation, getUNETRForSegmentation\n",
    "\n",
    "from transforms_dict import getSegmentationPostProcessingForLabel, getSegmentationPostProcessingForLabelOutput\n",
    "from utils import compute_mean_dice, getReducePlateauScheduler, getAdamOptimizer, loadExistingModel\n",
    "from utils import print_model_output, check_model_name, getDevice, getWorst, getBest\n",
    "from seg_data import getSegmentationDataset\n",
    "from seg_model import getUNetForSegmentation\n",
    "from transforms_dict import getSegmentationPostProcessingForLabel, getSegmentationPostProcessingForLabelOutput\n",
    "from utils import compute_mean_dice, getReducePlateauScheduler, getAdamOptimizer, loadExistingModel\n",
    "from utils import print_model_output, check_model_name, getDevice\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85692021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "dataset = \"GIN\"\n",
    "verbose = True\n",
    "augment = False\n",
    "n4 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18993c20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Modelname and device\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "set_determinism(seed=0)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "device = getDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75c0606d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from monai.transforms import Activations\n",
    "from torch import nn\n",
    "\n",
    "#Loss\n",
    "def loss_munet(preds, labels):\n",
    "    dice = 1-torch.div(\n",
    "        torch.sum(torch.mul(torch.mul(labels,preds),2)),\n",
    "        torch.sum(torch.mul(preds,preds)) + torch.sum(torch.mul(labels,labels))\n",
    "        )    \n",
    "    return dice\n",
    "\n",
    "loss_GDice = monai.losses.GeneralizedDiceLoss(other_act=nn.Softmax(dim=1))\n",
    "loss_DiceCE = monai.losses.DiceCELoss(other_act=nn.Softmax(dim=1))\n",
    "\n",
    "def loss_CE(input, target):\n",
    "        n_pred_ch, n_target_ch = input.shape[1], target.shape[1]\n",
    "        if n_pred_ch == n_target_ch:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        else:\n",
    "            target = torch.squeeze(target, dim=1)\n",
    "        target = target.long()\n",
    "        return nn.CrossEntropyLoss(reduction=\"mean\")(input, target)\n",
    "    \n",
    "def loss_GDiceCE(input, target, lambda_gdice=1.0, lambda_ce=0.5):    \n",
    "    GDice = loss_GDice(input, target)\n",
    "    CE = loss_CE(input, target)\n",
    "    GDiceCELoss = lambda_gdice*GDice + lambda_ce*CE\n",
    "    return GDiceCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0eff9631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Metric MUNet\n",
    "def metric_munet(preds, labels):  \n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    preds = preds.detach().cpu().numpy()    \n",
    "    labels[np.where(labels == np.amax(labels, axis=0))] = 1\n",
    "    labels[labels != 1] = 0\n",
    "    dice=2*np.sum(labels*preds,(1,2,3))/(np.sum((labels+preds),(1,2,3))+1)    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4e3619c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#postprocessing\n",
    "outputs_processing = getSegmentationPostProcessingForLabelOutput(axis=1)\n",
    "labels_processing = getSegmentationPostProcessingForLabel(axis=1)\n",
    "\n",
    "#activations\n",
    "softmax = Activations(other=nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "34173f90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Using GIN dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 60552.99it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 37063.07it/s]\n",
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 44779.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#dataloaders\n",
    "dataloaders, size = getSegmentationDataset(dataset=dataset, batch=1, augment=augment, training=False, n4=n4, labels=True, eval_augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7c10dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "ptdr = \"dataset3/Atlas/P56_Atlas_128_norm_id.nii.gz\"\n",
    "affine = nib.load(ptdr).affine\n",
    "header = nib.load(ptdr).header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e9b9649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_final/seg/test_labels_dicece.pth\n",
      "dataset3/GIN/LabelsBackFromAtlas/M872_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dataset3/GIN/LabelsBackFromAtlas/M874_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dataset3/GIN/LabelsBackFromAtlas/M875_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dataset3/GIN/LabelsBackFromAtlas/M877_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dataset3/GIN/LabelsBackFromAtlas/M886_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dataset3/GIN/LabelsBackFromAtlas/M8876_N4_o_128_ras_norm_id_fromdicece.nii.gz\n",
      "dice: 0.7291\n",
      "dices: 0.995, 0.564, 0.933, 0.424\n",
      "stdss: 0.001, 0.016, 0.004, 0.028\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model = getUNetForSegmentation()\n",
    "#model = getUNETRForSegmentation()\n",
    "modelnames = [\n",
    "    \"old_final/seg/test_labels_dicece.pth\",\n",
    "    #\"test_labels_unetr.pth\"\n",
    "    #\"test_labels_femina3_dicece.pth\",\n",
    "    #\"test_labels_femina3_gdice.pth\",\n",
    "    #\"test_labels_femina3_gdicefoc.pth\",\n",
    "    #\"test_labels_femina3_unetr_dicece.pth\",\n",
    "             ]\n",
    "\n",
    "softmax = Activations(other=nn.Softmax(dim=1))\n",
    "minn = 100\n",
    "\n",
    "for modelname in modelnames:\n",
    "    \n",
    "    modelname = check_model_name(modelname)\n",
    "    loadExistingModel(model, None, ft=modelname)\n",
    "    print(modelname)\n",
    "    model.eval()\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metrics = [[], [], [], []]        \n",
    "        phase = \"test\"\n",
    "        for i, data in enumerate(dataloaders[phase]):\n",
    "            if \"4mois_6827\" in data['img_meta_dict']['filename_or_obj'][0]:\n",
    "                continue\n",
    "            print(\"{}/{}\".format(\n",
    "                i, len(dataloaders[phase])), end='\\r'\n",
    "            )\n",
    "            inputs, labels = data[\"img\"].to(device), data[\"seg\"].to(device)\n",
    "            mask_filename = data['img_meta_dict']['filename_or_obj'][0].replace(\"/MRI/\", \"/Mask/\")\n",
    "            mask = torch.from_numpy(nib.load(mask_filename).get_fdata()).to(device).unsqueeze(0).unsqueeze(0)\n",
    "            mask = (mask != 0)\n",
    "            labels = labels * mask     \n",
    "            onehot_labels = monai.networks.utils.one_hot(labels, num_classes=4,dim=1)\n",
    "            \n",
    "            filename = data['img_meta_dict']['filename_or_obj'][0].split('/')[-1]\n",
    "            lbl_filename = data['seg_meta_dict']['filename_or_obj'][0].split('/')[-1]\n",
    "            labels = labels.squeeze(2)\n",
    "            \n",
    "            outputs = sliding_window_inference(inputs, (128, 128, 128), 1, model)   \n",
    "            probs = softmax(outputs) \n",
    "            probs_labels = torch.from_numpy(np.argmax(probs, axis=1)).unsqueeze(0).to(device) \n",
    "            probs_labels = probs_labels * mask        \n",
    "            onehot_probs = monai.networks.utils.one_hot(probs_labels, num_classes=4,dim=1).to(device)\n",
    "            \n",
    "            #print(onehot_probs.shape)\n",
    "            #print(onehot_probs[0,:,64,64,64]) \n",
    "            #print(onehot_labels.shape)\n",
    "            #print(onehot_labels[0,:,64,64,64])\n",
    "            \n",
    "            preds = [outputs_processing(pred) for pred in decollate_batch(outputs)]\n",
    "            labels = [label for label in decollate_batch(onehot_labels)]      \n",
    "            \n",
    "            dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)\n",
    "            dice_metric(y_pred=onehot_probs.squeeze(), y=onehot_labels.squeeze())\n",
    "            metric = dice_metric.aggregate()\n",
    "            \n",
    "            #if torch.mean(metric).item() < minn:\n",
    "            #    minn = torch.mean(metric).item()\n",
    "            #    print(minn)\n",
    "            #    print(filename)\n",
    "            \n",
    "            name = \"_\".join(data['img_meta_dict']['filename_or_obj'][0].split('/')[-1].split('.')[0].split('_')).replace(\"_affine_\",\"_\")\n",
    "            if \"unetr\" in modelname:\n",
    "                lossname = \"unetr\"\n",
    "            else:\n",
    "                lossname = modelname.split('.')[0].split('_')[-1]            \n",
    "            outputs_labels = outputs.detach().cpu().numpy()\n",
    "            outputs_labels = np.argmax(outputs_labels, axis=1)\n",
    "            outputs_labels = outputs_labels.squeeze()            \n",
    "            mask = mask.squeeze().cpu().numpy()\n",
    "            outputs_labels = outputs_labels * mask\n",
    "            outputname = \"dataset3/GIN/LabelsBackFromAtlas/\" + name + \"_from\" + lossname + \".nii.gz\"\n",
    "            nib.save(nib.Nifti1Image(outputs_labels, affine, header), outputname)  \n",
    "            print(outputname)\n",
    "            \n",
    "            for j in range(4):\n",
    "                metrics[j].append(metric[j].item())   \n",
    "   \n",
    "        #running_loss /= size[phase]\n",
    "        #print(metrics)\n",
    "        mean_metrics = [np.mean(x) for x in metrics]\n",
    "        std_metrics = [np.std(x) for x in metrics]\n",
    "        model_mean_dice = np.mean(mean_metrics)\n",
    "        print(\n",
    "            \"dice: {:.4f}\".format(\n",
    "                model_mean_dice\n",
    "            )\n",
    "        )\n",
    "        print(\"dices: {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(mean_metrics[0], mean_metrics[1], mean_metrics[2], mean_metrics[3]))\n",
    "        print(\"stdss: {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(std_metrics[0], std_metrics[1], std_metrics[2], std_metrics[3]))\n",
    "        print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08148eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_final/seg/test_labels_dicece.pth\n",
    "dice: 0.7291\n",
    "dices: 0.995, 0.564, 0.933, 0.424\n",
    "stdss: 0.001, 0.016, 0.004, 0.028\n",
    "    \n",
    "-----------------------------------------\n",
    "\n",
    "\n",
    "test_labels_unetr.pth\n",
    "dice: 0.6570\n",
    "dices: 0.994, 0.495, 0.918, 0.221\n",
    "stdss: 0.002, 0.006, 0.003, 0.054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e54b1412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_labels_femina3_unetr_dicece.pth\n",
      "0.7205321788787842\n",
      "2mois_7428_dki_F_N4_128_ras_norm_id.nii.gz\n",
      "0.6878746747970581\n",
      "4mois_7445_dki_M_N4_128_ras_norm_id.nii.gz\n",
      "0.6539582014083862\n",
      "4mois_7457_wt_F_N4_128_ras_norm_id.nii.gz\n",
      "dice: 0.7438\n",
      "dices: 0.998, 0.934, 0.688, 0.355\n",
      "stdss: 0.001, 0.008, 0.017, 0.114\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#model = getUNetForSegmentation()\n",
    "model = getUNETRForSegmentation()\n",
    "modelnames = [\n",
    "    #\"old_final/seg/test_labels_fce.pth\",   \n",
    "    #\"old_final/seg/test_labels_gdice.pth\",\n",
    "    #\"old_final/seg/test_labels_dicece.pth\",\n",
    "    #\"test_labels_unetr.pth\"\n",
    "    #\"test_labels_femina3_dicece.pth\",\n",
    "    #\"test_labels_femina3_gdice.pth\",\n",
    "    #\"test_labels_femina3_gdicefoc.pth\",\n",
    "    \"test_labels_femina3_unetr_dicece.pth\",\n",
    "             ]\n",
    "\n",
    "softmax = Activations(other=nn.Softmax(dim=1))\n",
    "minn = 100\n",
    "\n",
    "for modelname in modelnames:\n",
    "    \n",
    "    modelname = check_model_name(modelname)\n",
    "    loadExistingModel(model, None, ft=modelname)\n",
    "    print(modelname)\n",
    "    model.eval()\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metrics = [[], [], [], []]        \n",
    "        phase = \"test\"\n",
    "        for i, data in enumerate(dataloaders[phase]):\n",
    "            if \"4mois_6827\" in data['img_meta_dict']['filename_or_obj'][0]:\n",
    "                continue\n",
    "            print(\"{}/{}\".format(\n",
    "                i, len(dataloaders[phase])), end='\\r'\n",
    "            )\n",
    "            inputs, labels = data[\"img\"].to(device), data[\"seg\"].to(device)\n",
    "            mask_filename = data['img_meta_dict']['filename_or_obj'][0].replace(\"/MRI/\", \"/Labels2/\")\n",
    "            mask = torch.from_numpy(nib.load(mask_filename).get_fdata()).to(device).unsqueeze(0).unsqueeze(0)\n",
    "            mask = (mask != 0)\n",
    "            labels = labels * mask     \n",
    "            onehot_labels = monai.networks.utils.one_hot(labels, num_classes=4,dim=1)\n",
    "            \n",
    "            filename = data['img_meta_dict']['filename_or_obj'][0].split('/')[-1]\n",
    "            lbl_filename = data['seg_meta_dict']['filename_or_obj'][0].split('/')[-1]\n",
    "            labels = labels.squeeze(2)\n",
    "            \n",
    "            outputs = sliding_window_inference(inputs, (128, 128, 128), 1, model)   \n",
    "            probs = softmax(outputs) \n",
    "            probs_labels = torch.from_numpy(np.argmax(probs, axis=1)).unsqueeze(0).to(device) \n",
    "            probs_labels = probs_labels * mask        \n",
    "            onehot_probs = monai.networks.utils.one_hot(probs_labels, num_classes=4,dim=1).to(device)\n",
    "            \n",
    "            #print(onehot_probs.shape)\n",
    "            #print(onehot_probs[0,:,64,64,64]) \n",
    "            #print(onehot_labels.shape)\n",
    "            #print(onehot_labels[0,:,64,64,64])\n",
    "            \n",
    "            preds = [outputs_processing(pred) for pred in decollate_batch(outputs)]\n",
    "            labels = [label for label in decollate_batch(onehot_labels)]      \n",
    "            \n",
    "            dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)\n",
    "            dice_metric(y_pred=onehot_probs.squeeze(), y=onehot_labels.squeeze())\n",
    "            metric = dice_metric.aggregate()\n",
    "            \n",
    "            if torch.mean(metric).item() < minn:\n",
    "                minn = torch.mean(metric).item()\n",
    "                print(minn)\n",
    "                print(filename)\n",
    "            \n",
    "            name = \"_\".join(data['img_meta_dict']['filename_or_obj'][0].split('/')[-1].split('.')[0].split('_')).replace(\"_affine_\",\"_\")\n",
    "            if \"unetr\" in modelname:\n",
    "                lossname = \"unetr\"\n",
    "            else:\n",
    "                lossname = modelname.split('.')[0].split('_')[-1]\n",
    "            \n",
    "            #outputs_labels = outputs.detach().cpu().numpy()\n",
    "            #outputs_labels = np.argmax(outputs_labels, axis=1)\n",
    "            #outputs_labels = outputs_labels.squeeze()            \n",
    "            #mask = mask.squeeze().cpu().numpy()\n",
    "            #outputs_labels = outputs_labels * mask\n",
    "            #outputname = \"dataset3/Femina3/LabelsBackFromAtlas/\" + name + \"_from\" + lossname + \".nii.gz\"\n",
    "            #nib.save(nib.Nifti1Image(outputs_labels, affine, header), outputname)  \n",
    "            #print(outputname)\n",
    "            \n",
    "            for j in range(4):\n",
    "                metrics[j].append(metric[j].item())   \n",
    "   \n",
    "        #running_loss /= size[phase]\n",
    "        #print(metrics)\n",
    "        mean_metrics = [np.mean(x) for x in metrics]\n",
    "        std_metrics = [np.std(x) for x in metrics]\n",
    "        model_mean_dice = np.mean(mean_metrics)\n",
    "        print(\n",
    "            \"dice: {:.4f}\".format(\n",
    "                model_mean_dice\n",
    "            )\n",
    "        )\n",
    "        print(\"dices: {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(mean_metrics[0], mean_metrics[1], mean_metrics[2], mean_metrics[3]))\n",
    "        print(\"stdss: {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(std_metrics[0], std_metrics[1], std_metrics[2], std_metrics[3]))\n",
    "        print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_femina3_dicece.pth\n",
    "dice: 0.6978\n",
    "dices: 0.990, 0.873, 0.635, 0.294 // stdss: 0.012, 0.152, 0.112, 0.125\n",
    "----------\n",
    "test_labels_femina3_gdice.pth\n",
    "dice: 0.6786\n",
    "dices: 0.989, 0.861, 0.622, 0.243 // stdss: 0.012, 0.150, 0.111, 0.140\n",
    "----------\n",
    "test_labels_femina3_gdicefoc.pth\n",
    "dice: 0.6736\n",
    "dices: 0.989, 0.856, 0.608, 0.241 // stdss: 0.012, 0.149, 0.108, 0.140\n",
    "----------\n",
    "test_labels_femina3_unetr_dicece.pth\n",
    "dice: 0.7129\n",
    "dices: 0.990, 0.884, 0.651, 0.327 // stdss: 0.012, 0.154, 0.113, 0.116\n",
    "----------\n",
    "\n",
    "\n",
    "\n",
    "test_labels_femina3_dicece.pth\n",
    "dice: 0.7037\n",
    "dices: 0.997, 0.892, 0.642, 0.284\n",
    "stdss: 0.001, 0.156, 0.113, 0.108\n",
    "----------\n",
    "test_labels_femina3_gdice.pth\n",
    "dice: 0.6795\n",
    "dices: 0.997, 0.887, 0.616, 0.218\n",
    "stdss: 0.001, 0.155, 0.109, 0.111\n",
    "----------\n",
    "test_labels_femina3_gdicefoc.pth\n",
    "dice: 0.6819\n",
    "dices: 0.998, 0.893, 0.617, 0.219\n",
    "stdss: 0.001, 0.156, 0.109, 0.111\n",
    "----------\n",
    "test_labels_femina3_unetr_dicece.pth\n",
    "dice: 0.7293\n",
    "dices: 0.998, 0.907, 0.668, 0.345\n",
    "stdss: 0.001, 0.158, 0.116, 0.127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monai.config.deviceconfig.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c933b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994 - 0.010\n",
      "0.757 - 0.132\n",
      "0.233 - 0.038\n",
      "0.010 - 0.004\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'Labels', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromop_ants.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = \"_\".join(test_labels[i].split('/')[-1].split('_')[0:2])\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc916400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991 - 0.011\n",
      "0.739 - 0.129\n",
      "0.220 - 0.035\n",
      "0.007 - 0.003\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'Labels', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromsyn_ants.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = \"_\".join(test_labels[i].split('/')[-1].split('_')[0:2])\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5858e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9efe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4567bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71a99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f095c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a126f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986 - 0.011\n",
      "0.787 - 0.138\n",
      "0.647 - 0.112\n",
      "0.060 - 0.023\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'Labels', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromsyn_spm_c1c2c3.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = \"_\".join(test_labels[i].split('/')[-1].split('_')[0:2])\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa232b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992 - 0.011\n",
      "0.821 - 0.143\n",
      "0.701 - 0.119\n",
      "0.138 - 0.039\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'Labels', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromop_spm_c1c2c3.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = \"_\".join(test_labels[i].split('/')[-1].split('_')[0:2])\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c58a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e49c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.01 atlas\n",
    "0.9751 - 0.0060\n",
    "0.7725 - 0.0682\n",
    "0.6227 - 0.0551\n",
    "0.0487 - 0.0239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2933d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n",
      "0.9839 - 0.0060\n",
      "0.8026 - 0.0709\n",
      "0.6391 - 0.0566\n",
      "0.0260 - 0.0117\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'Labels2', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromsyn_spm.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1339b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.10 atlas\n",
    "0.9880 - 0.0059\n",
    "0.8353 - 0.0725\n",
    "0.6888 - 0.0592\n",
    "0.0824 - 0.0164\n",
    "\n",
    "t = 0.01 atlas\n",
    "0.9826 - 0.0059\n",
    "0.8092 - 0.0703\n",
    "0.6758 - 0.0576\n",
    "0.1058 - 0.0307\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddf19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "135\n",
      "nan - nan\n",
      "nan - nan\n",
      "nan - nan\n",
      "nan - nan\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromsyn_spm.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0020127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb15cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18493a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7799be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88d6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61ae74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379de0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51753356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n",
      "0.9882 - 0.0056\n",
      "0.7606 - 0.0662\n",
      "0.2251 - 0.0199\n",
      "0.0054 - 0.0021\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromsyn.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'Femina3', 'LabelsBackFromAtlas', '*_id_fromop.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d18c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1de21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a7a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83443053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17dbb0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999 - 0.000\n",
      "0.775 - 0.016\n",
      "0.979 - 0.001\n",
      "0.646 - 0.015\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromop2.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = test_labels[i].split('/')[-1].split('_')[0]\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b99ad71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999 - 0.000\n",
      "0.758 - 0.015\n",
      "0.978 - 0.001\n",
      "0.630 - 0.027\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromdl.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = test_labels[i].split('/')[-1].split('_')[0]\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d0642aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999 - 0.000\n",
      "0.767 - 0.018\n",
      "0.979 - 0.001\n",
      "0.630 - 0.031\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "test_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromunetr.nii.gz')))\n",
    "\n",
    "\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_frompair2.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(test_labels)):\n",
    "    mouseid = test_labels[i].split('/')[-1].split('_')[0]\n",
    "    a = [s for s in ants_labels if mouseid in s][0]\n",
    "    b = [s for s in opsy_labels if mouseid in s][0]\n",
    "    ants_lbl = torch.from_numpy(nib.load(a).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(b).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    mask = (opsy_lbl != 0)\n",
    "    ants_lbl = ants_lbl * mask\n",
    "    \n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.3f} - {:.3f}\".format(np.mean(i),np.std(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019cb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67977295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "hawaiian-ecology",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ants_labels)):\n\u001b[1;32m     16\u001b[0m     ants_lbl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(nib\u001b[38;5;241m.\u001b[39mload(ants_labels[i])\u001b[38;5;241m.\u001b[39mget_fdata())\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.LongTensor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     opsy_lbl \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopsy_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.LongTensor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     dice \u001b[38;5;241m=\u001b[39m dice_metric(opsy_lbl, ants_lbl)\n\u001b[1;32m     19\u001b[0m     c_1\u001b[38;5;241m.\u001b[39mappend(dice[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/nibabel/dataobj_images.py:355\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/nibabel/arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124;03m\"\"\" Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/nibabel/arrayproxy.py:358\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    356\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/nibabel/arrayproxy.py:332\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \\\n\u001b[1;32m    330\u001b[0m         canonical_slicers((), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m                               \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m                               \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(fileobj,\n\u001b[1;32m    340\u001b[0m                      slicer,\n\u001b[1;32m    341\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m                      order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder,\n\u001b[1;32m    345\u001b[0m                      lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock)\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/nibabel/volumeutils.py:522\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    521\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[0;32m--> 522\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/gzip.py:292\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/usr/lib/python3.8/gzip.py:487\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m    485\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m--> 487\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "import nibabel as nib\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromop.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "placed-portrait",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "0.9897 - 0.0014\n",
      "0.5825 - 0.0788\n",
      "0.9222 - 0.0123\n",
      "0.4605 - 0.1378\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromop.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endangered-montreal",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897 - 0.0012\n",
      "0.5926 - 0.0636\n",
      "0.9210 - 0.0106\n",
      "0.4789 - 0.1224\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromdl.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac487ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c09b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c479dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "0.9895 - 0.0015\n",
      "0.5854 - 0.0756\n",
      "0.9199 - 0.0126\n",
      "0.4605 - 0.1335\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_frompair2.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8037836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "0.9893 - 0.0016\n",
      "0.5792 - 0.0734\n",
      "0.9185 - 0.0146\n",
      "0.4772 - 0.1428\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromop2.nii.gz')))\n",
    "\n",
    "print(len(ants_labels))\n",
    "print(len(opsy_labels))\n",
    "\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2047a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5ecd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595157ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ca44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2a5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ed5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "0.9971 - 0.0005\n",
      "0.8540 - 0.0397\n",
      "0.9741 - 0.0049\n",
      "0.7553 - 0.0311\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torchmetrics\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_fromop.nii.gz')))\n",
    "opsy_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'LabelsBackFromAtlas', '*_id_frompair.nii.gz')))\n",
    "\n",
    "#dice_metric = DiceMetric(include_background=True, reduction=\"mean_channel\", get_not_nans=False)           \n",
    "dice_metric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=4)\n",
    "\n",
    "c_1 = []\n",
    "c_2 = []\n",
    "c_3 = []\n",
    "c_4 = []\n",
    "for i in range(len(ants_labels)):\n",
    "    ants_lbl = torch.from_numpy(nib.load(ants_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    opsy_lbl = torch.from_numpy(nib.load(opsy_labels[i]).get_fdata()).ravel().type('torch.LongTensor')\n",
    "    dice = dice_metric(opsy_lbl, ants_lbl)\n",
    "    c_1.append(dice[0])\n",
    "    c_2.append(dice[1])\n",
    "    c_3.append(dice[2])\n",
    "    c_4.append(dice[3])\n",
    "    \n",
    "for i in [c_1,c_2,c_3,c_4]:\n",
    "    print(\"{:.4f} - {:.4f}\".format(np.mean(i),np.std(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1374d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
