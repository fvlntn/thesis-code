{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b347041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reg_mri\n",
    "import os\n",
    "from glob import glob\n",
    "from utils import compute_mean_dice\n",
    "import nibabel as nib\n",
    "from scipy.spatial.distance import dice\n",
    "import numpy as np\n",
    "import itk\n",
    "import SimpleITK as sitk\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from transforms_dict import getRegistrationEvalInverseTransformForMRI, SaveTransformForMRI\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "import subprocess\n",
    "from monai.transforms import AsDiscrete, MaskIntensity, RandAffine, Affine\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2708a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import AsDiscrete, MaskIntensity, RandAffine, Affine\n",
    "from monai.utils import set_determinism\n",
    "from monai.losses import LocalNormalizedCrossCorrelationLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "import utils_parser\n",
    "from reg_data import getRegistrationDataset\n",
    "from reg_model import getRegistrationModel\n",
    "from utils import compute_mean_dice, getAdamOptimizer, getReducePlateauScheduler, loadExistingModel, getDevice\n",
    "from utils import print_model_output, print_weights, add_weights_to_name, compute_landmarks_distance_local\n",
    "from loss import compute_affine_loss, get_jacobian, antifolding_loss, JacobianDet\n",
    "from loss import get_deformable_registration_loss_from_weights, get_affine_registration_loss_from_weights, jacobian_loss\n",
    "from models import TrilinearLocalNet\n",
    "from torchinfo import summary\n",
    "from miseval import evaluate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc581aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.utils import meshgrid_ij\n",
    "\n",
    "def compute_ddfcompare_loss(u1, u2):        \n",
    "    image_size=(128,128,128)\n",
    "    warp_stn = Warp(\"bilinear\", \"reflection\")\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0)  # (spatial_dims, ...)\n",
    "    X = grid.to(dtype=torch.float)\n",
    "    X_x = X[0,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    X_y = X[1,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    X_z = X[2,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X = X + u1[0,:,:,:,:]\n",
    "    #print('-'*10)\n",
    "    #p = [72,83,94]\n",
    "    #print('X: ' + str(X[:,p[0],p[1],p[2]]))\n",
    "    #print('u1: ' + str(u1[0,:,p[0],p[1],p[2]]))\n",
    "    #print('u1X: ' + str(u1X[:,p[0],p[1],p[2]]))\n",
    "    u1X_x = u1X[0,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_y = u1X[1,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_z = u1X[2,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u2u1X_x = warp_stn(u1X_x, u2)        \n",
    "    u2u1X_y = warp_stn(u1X_y, u2)    \n",
    "    u2u1X_z = warp_stn(u1X_z, u2)    \n",
    "    u2u1X = torch.stack([u2u1X_x.squeeze(), u2u1X_y.squeeze(), u2u1X_z.squeeze()])\n",
    "    #print('u2u1X: ' + str(u2u1X[:,p[0],p[1],p[2]]))\n",
    "    #print('-'*10)\n",
    "    loss = torch.nn.MSELoss()\n",
    "    noise_ddfcompare_loss = loss(u2u1X, X)\n",
    "    \n",
    "    return noise_ddfcompare_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6550d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2102)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.networks.utils import meshgrid_ij\n",
    "from monai.transforms import AffineGrid\n",
    "\n",
    "def get_affine_warp(affine):\n",
    "    image_size=(128,128,128)\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0).to(dtype=torch.float)\n",
    "    affine_grid = affine_transform(affine)\n",
    "    affine_warp = affine_grid - grid\n",
    "    return affine_warp\n",
    "\n",
    "def affine_transform(theta):\n",
    "    image_size=(128,128,128)\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0).to(dtype=torch.float)\n",
    "    grid_padded = torch.cat([grid, torch.ones_like(grid[:1])])\n",
    "    grid_warped = torch.einsum(\"qijk,bpq->bpijk\", grid_padded, theta.reshape(-1, 3, 4))\n",
    "    return grid_warped\n",
    "\n",
    "affine_grid = AffineGrid(rotate_params=(-np.pi/90, np.pi/90, np.pi/90), \n",
    "                    translate_params=(1.21,1.37,-1.24), \n",
    "                    scale_params=(1.027,1.012,0.984), \n",
    "                    device=None, \n",
    "                    dtype=np.float32,\n",
    "                    affine=None)\n",
    "_, A = affine_grid(spatial_size=(128,128,128))\n",
    "A = A.reshape(16)[:12]\n",
    "A_inv = torch.linalg.inv(torch.cat((A, torch.Tensor([0,0,0,1])), 0).reshape(4,4)).reshape(16)[:12]\n",
    "\n",
    "A_warp = get_affine_warp(A)\n",
    "A_inv_warp = get_affine_warp(A_inv)\n",
    "\n",
    "compute_ddfcompare_loss(A_warp, A_inv_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_grid = AffineGrid(rotate_params=(0, 0, 0), \n",
    "                    translate_params=(0,0,0), \n",
    "                    scale_params=(1,1,1), \n",
    "                    device=None, \n",
    "                    dtype=np.float32,\n",
    "                    affine=None)\n",
    "_, affine_matrix = affine_grid(spatial_size=(128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4229f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d487489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from monai.networks.utils import meshgrid_ij\n",
    "from monai.transforms import Affine\n",
    "\n",
    "def affine_transform(theta: torch.Tensor):\n",
    "    grid_padded = torch.cat([grid, torch.ones_like(grid[:1])])\n",
    "    grid_warped = torch.einsum(\"qijk,bpq->bpijk\", grid_padded, theta.reshape(-1, 3, 4))\n",
    "    return grid_warped\n",
    "\n",
    "\n",
    "def get_affine(theta=0, tx=0, ty=0, tz=0, sx=1, sy=1, sz=1):\n",
    "    return torch.tensor([sx*np.cos(theta), -np.sin(theta), 0, tx,\n",
    "                         np.sin(theta), sy*np.cos(theta), 0, ty,\n",
    "                         0, 0, sz*1, tz], dtype=torch.float)\n",
    "\n",
    "def get_affine_warp(affine):\n",
    "    image_size=(128,128,128)\n",
    "    grid = get_reference_grid(image_size)\n",
    "    print(grid[:,72,85,51])\n",
    "    affine_grid = affine_transform(affine)\n",
    "    print(affine_grid[0,:,72,85,51])\n",
    "    ##print('-'*10)\n",
    "    affine_warp = affine_grid - grid\n",
    "    print(affine_warp[0,:,72,85,51])\n",
    "    print('-'*10)\n",
    "    return affine_warp\n",
    "\n",
    "def get_rotation_matrix_center(theta, tx, ty):\n",
    "    translation_1 = torch.tensor([1, 0, 0, -tx,\n",
    "                                0, 1, 0, -ty,\n",
    "                                0, 0, 1, 0], dtype=torch.float)  \n",
    "    translation_1 = torch.cat((translation_1, torch.Tensor([0,0,0,1])), 0).reshape(4,4)\n",
    "    \n",
    "    rotation = torch.tensor([np.cos(theta), -np.sin(theta), 0, 0,\n",
    "                         np.sin(theta), sy*np.cos(theta), 0, 0,\n",
    "                         0, 0, 1, 0], dtype=torch.float)\n",
    "    rotation = torch.cat((rotation, torch.Tensor([0,0,0,1])), 0).reshape(4,4)\n",
    "    translation_2 = torch.tensor([1, 0, 0, tx,\n",
    "                                0, 1, 0, ty,\n",
    "                                0, 0, 1, 0], dtype=torch.float)  \n",
    "    translation_2 = torch.cat((translation_2, torch.Tensor([0,0,0,1])), 0).reshape(4,4)\n",
    "    out = translation_2*rotation*translation_1\n",
    "    out = out.reshape(16)[:12]\n",
    "    return out\n",
    "\n",
    "#ptdr = get_rotation_matrix_center(np.pi/2,64,64)\n",
    "    \n",
    "\n",
    "alpha = np.pi/2\n",
    "tx = 64\n",
    "ty = 64\n",
    "tz = 0\n",
    "sx = 1\n",
    "sy = 1\n",
    "sz = 1\n",
    "A = get_affine(alpha, tx, ty, tz, sx, sy, sz)\n",
    "A_inv = torch.linalg.inv(torch.cat((A, torch.Tensor([0,0,0,1])), 0).reshape(4,4)).reshape(16)[:12]\n",
    "warp = get_affine_warp(A)\n",
    "warp_inv = get_affine_warp(A_inv)\n",
    "compute_ddfcompare_loss(warp, warp_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from monai.networks.utils import meshgrid_ij\n",
    "from monai.transforms import AffineGrid\n",
    "\n",
    "affine_grid = AffineGrid(rotate_params=(0, 0, 0), \n",
    "                    translate_params=(0,0,0), \n",
    "                    scale_params=(1,1,1), \n",
    "                    device=None, \n",
    "                    dtype=np.float32,\n",
    "                    affine=None)\n",
    "_, affine_matrix = affine_grid(spatial_size=(128,128,128))\n",
    "affine_matrix_inv = torch.linalg.inv(affine_matrix)\n",
    "print(affine_matrix)\n",
    "print(affine_matrix_inv)\n",
    "affine_matrix = affine_matrix.reshape(16)[:12]\n",
    "affine_matrix_inv = affine_matrix_inv.reshape(16)[:12]\n",
    "\n",
    "def affine_transform(theta: torch.Tensor):\n",
    "    grid_padded = torch.cat([grid, torch.ones_like(grid[:1])])\n",
    "    grid_warped = torch.einsum(\"qijk,bpq->bpijk\", grid_padded, theta.reshape(-1, 3, 4))\n",
    "    return grid_warped\n",
    "\n",
    "\n",
    "def get_affine(theta=0, tx=0, ty=0, tz=0, sx=1, sy=1, sz=1):\n",
    "    return torch.tensor([sx*np.cos(theta), -np.sin(theta), 0, tx,\n",
    "                         np.sin(theta), sy*np.cos(theta), 0, ty,\n",
    "                         0, 0, sz*1, tz], dtype=torch.float)\n",
    "\n",
    "def get_reference_grid(image_size: Union[Tuple[int], List[int]]) -> torch.Tensor:\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0)  # (spatial_dims, ...)\n",
    "    return grid.to(dtype=torch.float)\n",
    "\n",
    "def get_affine_warp(affine):\n",
    "    image_size=(128,128,128)\n",
    "    grid = get_reference_grid(image_size)\n",
    "    print(grid[:,72,85,51])\n",
    "    affine_grid = affine_transform(affine)\n",
    "    print(affine_grid[0,:,72,85,51])\n",
    "    ##print('-'*10)\n",
    "    affine_warp = affine_grid - grid\n",
    "    print(affine_warp[0,:,72,85,51])\n",
    "    print('-'*10)\n",
    "    return affine_warp\n",
    "\n",
    "print(affine_matrix.shape)\n",
    "affine_warp = get_affine_warp(affine_matrix)\n",
    "print(affine_warp.shape)\n",
    "affine_warp_inv = get_affine_warp(affine_matrix_inv)\n",
    "\n",
    "compute_ddfcompare_loss(affine_warp, affine_warp_inv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
