{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "300883df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import monai\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.utils import set_determinism\n",
    "import numpy as np\n",
    "\n",
    "from seg_data import getSegmentationDataset\n",
    "from seg_model import getUNetForSegmentation, getUNETRForSegmentation\n",
    "from transforms_dict import getSegmentationPostProcessingForLabel, getSegmentationPostProcessingForLabelOutput\n",
    "from utils import compute_mean_dice, getReducePlateauScheduler, getAdamOptimizer, loadExistingModel\n",
    "from utils import print_model_output, check_model_name, getDevice, getWorst, getBest\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import decollate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85692021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "dataset = \"IRIS\"\n",
    "phase = \"test\"\n",
    "number = 10\n",
    "verbose = True\n",
    "augment = False\n",
    "n4 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18993c20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Modelname and device\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "set_determinism(seed=0)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "device = getDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c0606d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from monai.transforms import Activations\n",
    "from torch import nn\n",
    "\n",
    "#Loss\n",
    "def loss_munet(preds, labels):\n",
    "    dice = 1-torch.div(\n",
    "        torch.sum(torch.mul(torch.mul(labels,preds),2)),\n",
    "        torch.sum(torch.mul(preds,preds)) + torch.sum(torch.mul(labels,labels))\n",
    "        )    \n",
    "    return dice\n",
    "\n",
    "loss_GDice = monai.losses.GeneralizedDiceLoss(other_act=nn.Softmax(dim=1))\n",
    "loss_DiceCE = monai.losses.DiceCELoss(other_act=nn.Softmax(dim=1))\n",
    "\n",
    "def loss_CE(input, target):\n",
    "        n_pred_ch, n_target_ch = input.shape[1], target.shape[1]\n",
    "        if n_pred_ch == n_target_ch:\n",
    "            target = torch.argmax(target, dim=1)\n",
    "        else:\n",
    "            target = torch.squeeze(target, dim=1)\n",
    "        target = target.long()\n",
    "        return nn.CrossEntropyLoss(reduction=\"mean\")(input, target)\n",
    "    \n",
    "def loss_GDiceCE(input, target, lambda_gdice=1.0, lambda_ce=0.5):    \n",
    "    GDice = loss_GDice(input, target)\n",
    "    CE = loss_CE(input, target)\n",
    "    GDiceCELoss = lambda_gdice*GDice + lambda_ce*CE\n",
    "    return GDiceCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eff9631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Metric MUNet\n",
    "def metric_munet(preds, labels):  \n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    preds = preds.detach().cpu().numpy()    \n",
    "    labels[np.where(labels == np.amax(labels, axis=0))] = 1\n",
    "    labels[labels != 1] = 0\n",
    "    dice=2*np.sum(labels*preds,(1,2,3))/(np.sum((labels+preds),(1,2,3))+1)    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3619c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#postprocessing\n",
    "outputs_processing = getSegmentationPostProcessingForLabelOutput()\n",
    "labels_processing = getSegmentationPostProcessingForLabel()\n",
    "\n",
    "#activations\n",
    "softmax = Activations(other=nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34173f90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Using IRIS dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 397929.38it/s]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:00<00:00, 266408.15it/s]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:00<00:00, 494156.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#dataloaders\n",
    "dataloaders, size = getSegmentationDataset(dataset=dataset, batch=1, augment=augment, training=False, n4=n4, labels=True, eval_augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54b1412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/82\r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ground truth has differing shape ((1, 1, 128, 128, 128)) from input ((1, 4, 128, 128, 128))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m sliding_window_inference(inputs, (\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m), \u001b[38;5;241m4\u001b[39m, model)                \n\u001b[0;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_GDiceCE\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#loss = loss_DiceCE(outputs, labels)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m preds \u001b[38;5;241m=\u001b[39m [outputs_processing(pred) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m decollate_batch(outputs)]\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mloss_GDiceCE\u001b[0;34m(input, target, lambda_gdice, lambda_ce)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_GDiceCE\u001b[39m(\u001b[38;5;28minput\u001b[39m, target, lambda_gdice\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, lambda_ce\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):    \n\u001b[0;32m---> 25\u001b[0m     GDice \u001b[38;5;241m=\u001b[39m \u001b[43mloss_GDice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     CE \u001b[38;5;241m=\u001b[39m loss_CE(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m     27\u001b[0m     GDiceCELoss \u001b[38;5;241m=\u001b[39m lambda_gdice\u001b[38;5;241m*\u001b[39mGDice \u001b[38;5;241m+\u001b[39m lambda_ce\u001b[38;5;241m*\u001b[39mCE\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/Mousenet/venv/lib/python3.8/site-packages/monai/losses/dice.py:337\u001b[0m, in \u001b[0;36mGeneralizedDiceLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground truth has differing shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) from input (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# reducing only spatial dimensions (not batch nor channels)\u001b[39;00m\n\u001b[1;32m    340\u001b[0m reduce_axis: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape))\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAssertionError\u001b[0m: ground truth has differing shape ((1, 1, 128, 128, 128)) from input ((1, 4, 128, 128, 128))"
     ]
    }
   ],
   "source": [
    "model = getUNetForSegmentation()\n",
    "modelname = \"test_seg_labels.pth\"\n",
    "#modelnames = \n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "modelname = check_model_name(modelname)\n",
    "loadExistingModel(model, None, ft=modelname)\n",
    "model.eval()\n",
    "\n",
    "scores_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    metrics = [[], [], [], []]\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloaders[phase]):\n",
    "        print(\"{}/{}\".format(\n",
    "            i, len(dataloaders[phase])), end='\\r'\n",
    "        )\n",
    "        inputs, labels = data[\"img\"].to(device), data[\"seg\"].to(device)\n",
    "        filename = data['img_meta_dict']['filename_or_obj'][0].split('/')[-1]\n",
    "        labels = labels.squeeze(2)\n",
    "        outputs = sliding_window_inference(inputs, (96, 96, 96), 4, model)                \n",
    "        loss = loss_GDiceCE(outputs, labels)\n",
    "        #loss = loss_DiceCE(outputs, labels)\n",
    "        preds = [outputs_processing(pred) for pred in decollate_batch(outputs)]\n",
    "        labels = [labels_processing(label) for label in decollate_batch(labels)]\n",
    "        running_loss += loss.item() * inputs.size(0)                       \n",
    "        \n",
    "        for j in range(len(preds)):\n",
    "            metric = metric_munet(preds[j], labels[j])                     \n",
    "            for k in range(4):\n",
    "                metrics[k].append(metric[k])     \n",
    "        metric_mean = np.mean(metric)\n",
    "        scores_list.append([filename, loss.item(), metric_mean])\n",
    "            \n",
    "    running_loss /= size[phase]\n",
    "    epoch_metrics = [np.mean(x) for x in metrics]\n",
    "    epoch_metric = np.mean(epoch_metrics)\n",
    "    print(\n",
    "        \"{}: loss: {:.4f}, dice: {:.4f}\".format(\n",
    "            phase, running_loss, epoch_metric\n",
    "        )\n",
    "    )\n",
    "    print(\"dices: {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(epoch_metrics[0], epoch_metrics[1], epoch_metrics[2], epoch_metrics[3]))\n",
    "\n",
    "getWorst(scores_list, number)\n",
    "getBest(scores_list, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-ecology",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-montreal",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-portrait",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
