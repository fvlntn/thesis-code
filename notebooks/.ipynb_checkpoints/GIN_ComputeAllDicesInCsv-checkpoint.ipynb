{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9458ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import torch\n",
    "import torchmetrics\n",
    "import nibabel as nib\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "region_names = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac5ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-6\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "studies = [\"OP-0\",\n",
    "           \"OP-1\",\n",
    "           \"OP-2\",\n",
    "           \"OP-3\",\n",
    "           \"OP-4\",\n",
    "           \"OP-5\",\n",
    "           \"OP-6\",\n",
    "           \"Pair-0\",\n",
    "           \"Pair-1\",\n",
    "           \"Pair-2\",\n",
    "           \"Pair-3\",\n",
    "           \"Pair-4\",\n",
    "           \"Pair-5\",\n",
    "           \"Pair-6\", \n",
    "          ]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"Labels\", \"*.nii.gz\"))))\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0] \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_labels[i])):\n",
    "        id = method_labels[i][j].split('/')[-1].split('_')[0]    \n",
    "        labels = torch.from_numpy(nib.load(method_labels[i][j]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "        values = dicemetric(labels,map6)\n",
    "        for k in range(len(region_names)):\n",
    "            dice = values[k].item()\n",
    "            struct = region_names[k]\n",
    "            volume = ((labels==k).sum().item())*(0.12**3)\n",
    "            line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id, \"dice\": dice, \"volume\": volume}  \n",
    "            list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_lambda2_results_individual_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3ffbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-6\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "studies = [\"OP-0\",\n",
    "           \"OP-1\",\n",
    "           \"OP-2\",\n",
    "           \"OP-3\",\n",
    "           \"OP-4\",\n",
    "           \"OP-5\",\n",
    "           \"OP-6\",\n",
    "           \"Pair-0\",\n",
    "           \"Pair-1\",\n",
    "           \"Pair-2\",\n",
    "           \"Pair-3\",\n",
    "           \"Pair-4\",\n",
    "           \"Pair-5\",\n",
    "           \"Pair-6\", \n",
    "          ]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"Labels\", \"*.nii.gz\"))))\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j1 in range(len(method_labels[i])):    \n",
    "        labels_j1 = torch.from_numpy(nib.load(method_labels[i][j1]).get_fdata().ravel()).type('torch.LongTensor')  \n",
    "        id1 = method_labels[i][j1].split('/')[-1].split('_')[0]      \n",
    "        for j2 in range(len(method_labels[i])):  \n",
    "            id2 = method_labels[i][j2].split('/')[-1].split('_')[0] \n",
    "            \n",
    "            if id1 == id2:            \n",
    "                output = 'temp_crossdice.nii.gz'\n",
    "                command = ['antsApplyTransforms']\n",
    "                command.extend(['-d', '3'])\n",
    "                command.extend(['-i', method_labels[i][j2]])\n",
    "                command.extend(['-r', method_labels[i][j1]])\n",
    "                command.extend(['-o', output])\n",
    "                command.extend(['-n', 'MultiLabel'])\n",
    "                command.extend(['-t', method_bck_wrps[i][j1]])\n",
    "                command.extend(['-t', method_fwd_wrps[i][j2]])\n",
    "                subprocess.call(command) \n",
    "\n",
    "                labels_j2_to_j1 = torch.from_numpy(nib.load(output).get_fdata().ravel()).type('torch.LongTensor')\n",
    "                values = dicemetric(labels_j1,labels_j2_to_j1)\n",
    "\n",
    "\n",
    "\n",
    "                for k in range(len(region_names)):\n",
    "                    dice = values[k].item()\n",
    "                    struct = region_names[k]\n",
    "                    volume = ((labels==k).sum().item())*(0.12**3)\n",
    "                    line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id2, \"target\": id1, \"dice\": dice, \"volume\": volume}  \n",
    "                    list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_lambda2_results_selfdice_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a17815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-2\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "studies = [\"OP-5\",\n",
    "           \"Pair-2\",\n",
    "          ]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"Labels\", \"*.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"Labels\", \"*.nii.gz\"))))\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j1 in range(len(method_labels[i])):    \n",
    "        labels_j1 = torch.from_numpy(nib.load(method_labels[i][j1]).get_fdata().ravel()).type('torch.LongTensor')  \n",
    "        id1 = method_labels[i][j1].split('/')[-1].split('_')[0]      \n",
    "        for j2 in range(len(method_labels[i])):  \n",
    "            id2 = method_labels[i][j2].split('/')[-1].split('_')[0] \n",
    "            \n",
    "            if id1 != id2:            \n",
    "                output = 'temp_crossdice.nii.gz'\n",
    "                command = ['antsApplyTransforms']\n",
    "                command.extend(['-d', '3'])\n",
    "                command.extend(['-i', method_labels[i][j2]])\n",
    "                command.extend(['-r', method_labels[i][j1]])\n",
    "                command.extend(['-o', output])\n",
    "                command.extend(['-n', 'MultiLabel'])\n",
    "                command.extend(['-t', method_bck_wrps[i][j1]])\n",
    "                command.extend(['-t', method_fwd_wrps[i][j2]])\n",
    "                subprocess.call(command) \n",
    "\n",
    "                labels_j2_to_j1 = torch.from_numpy(nib.load(output).get_fdata().ravel()).type('torch.LongTensor')\n",
    "                values = dicemetric(labels_j1,labels_j2_to_j1)\n",
    "\n",
    "\n",
    "\n",
    "                for k in range(len(region_names)):\n",
    "                    dice = values[k].item()\n",
    "                    struct = region_names[k]\n",
    "                    volume = ((labels==k).sum().item())*(0.12**3)\n",
    "                    line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id2, \"target\": id1, \"dice\": dice, \"volume\": volume}  \n",
    "                    list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_lambda2_results_crossdice_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2dd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.utils import meshgrid_ij\n",
    "\n",
    "def getDevice():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_symcompare_loss(u1, u2, warp_stn, img_size=128):\n",
    "    device = getDevice()\n",
    "    warp_stn = warp_stn.to(device)\n",
    "    image_size = (img_size, img_size, img_size)\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0)  # (spatial_dims, ...)\n",
    "    X = grid.to(dtype=torch.float).to(device)\n",
    "    u1X = X + u1[0,:,:,:,:]\n",
    "    u1X_x = u1X[0,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_y = u1X[1,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_z = u1X[2,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u2u1X_x = warp_stn(u1X_x, u2)\n",
    "    u2u1X_y = warp_stn(u1X_y, u2)\n",
    "    u2u1X_z = warp_stn(u1X_z, u2)\n",
    "    u2u1X = torch.stack([u2u1X_x.squeeze(), u2u1X_y.squeeze(), u2u1X_z.squeeze()])\n",
    "    loss = torch.nn.MSELoss()\n",
    "    sym_inv_loss = loss(u2u1X, X)\n",
    "    return sym_inv_loss\n",
    "\n",
    "\n",
    "def get_sym_loss(u1, u2, weight, warp_stn, img_size=128):\n",
    "    return 0.5 * weight * (get_symcompare_loss(u1, u2, warp_stn, img_size) + get_symcompare_loss(u2, u1, warp_stn, img_size))\n",
    "\n",
    "\n",
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"OP-0\",\n",
    "           \"OP-1\",\n",
    "           \"OP-2\",\n",
    "           \"OP-3\",\n",
    "           \"OP-4\",\n",
    "           \"OP-5\",\n",
    "           \"OP-6\",\n",
    "           \"Pair-0\",\n",
    "           \"Pair-1\",\n",
    "           \"Pair-2\",\n",
    "           \"Pair-3\",\n",
    "           \"Pair-4\",\n",
    "           \"Pair-5\",\n",
    "           \"Pair-6\", \n",
    "          ]\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.001\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1.0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_10\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_100\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_1000\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_1\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_2\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_3\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_4\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_5\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_6\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "list_dict = []\n",
    "sym_warp_reflection = Warp(\"bilinear\", \"reflection\").to(getDevice())\n",
    "    \n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_fwd_wrps[i])):    \n",
    "        id1 = method_fwd_wrps[i][j].split('/')[-1].split('_')[0]  \n",
    "        multiplier = torch.tensor([-1, -1, 1]).view(1, 3, 1, 1, 1)\n",
    "        u1 = nib.load(method_fwd_wrps[i][j]).get_fdata()\n",
    "        u1 = torch.from_numpy(np.transpose(u1, (3, 4, 0, 1, 2)))\n",
    "        u1 = u1 * multiplier\n",
    "        u1 = u1.to(getDevice())\n",
    "        \n",
    "        u2 = nib.load(method_bck_wrps[i][j]).get_fdata()\n",
    "        u2 = torch.from_numpy(np.transpose(u2, (3, 4, 0, 1, 2)))\n",
    "        u2 = u2 * multiplier\n",
    "        u2 = u2.to(getDevice())\n",
    "        \n",
    "        \n",
    "        symloss = get_sym_loss(u1, u2, 1.0, sym_warp_reflection)            \n",
    "        line_dict = {\"method\": method, \"mouse\": id1, \"loss\": symloss.item()}\n",
    "        \n",
    "        list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_lambda2_results_invsymloss_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73ffe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab14de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69706b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"Affine\",\n",
    "           \"SyN\",\n",
    "           \"SyN-Mask\",\n",
    "           \"SyN-Mean\",\n",
    "           #\n",
    "           \"DL-IRIS-sym\",\n",
    "           \"OP-sym\",\n",
    "           \"Pair-sym\",\n",
    "           #\n",
    "           \"DL-IRIS\",\n",
    "           \"OP\",\n",
    "           \"Pair\",\n",
    "          ]\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_affine_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mask', 'Labels', \"*_deformable.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "#\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris-sym', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_0', 'Labels', '*.nii.gz'))))\n",
    "#\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda1_1.0', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda1_3', 'Labels', '*.nii.gz'))))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0] \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_labels[i])):\n",
    "        id = method_labels[i][j].split('/')[-1].split('_')[0]    \n",
    "        labels = torch.from_numpy(nib.load(method_labels[i][j]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "        values = dicemetric(labels,map6)\n",
    "        for k in range(len(region_names)):\n",
    "            dice = values[k].item()\n",
    "            struct = region_names[k]\n",
    "            volume = ((labels==k).sum().item())*(0.12**3)\n",
    "            line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id, \"dice\": dice, \"volume\": volume}  \n",
    "            list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_results_individual_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e2517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"SyN\",\n",
    "           \"SyN-Mask\",\n",
    "           \"SyN-Mean\",\n",
    "           \"DL-IRIS-sym\",\n",
    "           \"OP-sym\",\n",
    "           \"Pair-sym\",\n",
    "          ]\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mask', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris-sym', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_0', 'Labels', '*.nii.gz'))))\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j1 in range(len(method_labels[i])):    \n",
    "        labels_j1 = torch.from_numpy(nib.load(method_labels[i][j1]).get_fdata().ravel()).type('torch.LongTensor')  \n",
    "        id1 = method_labels[i][j1].split('/')[-1].split('_')[0]      \n",
    "        for j2 in range(len(method_labels[i])):  \n",
    "            output = 'temp_crossdice.nii.gz'\n",
    "            command = ['antsApplyTransforms']\n",
    "            command.extend(['-d', '3'])\n",
    "            command.extend(['-i', method_labels[i][j2]])\n",
    "            command.extend(['-r', method_labels[i][j1]])\n",
    "            command.extend(['-o', output])\n",
    "            command.extend(['-n', 'MultiLabel'])\n",
    "            command.extend(['-t', method_bck_wrps[i][j1]])\n",
    "            command.extend(['-t', method_fwd_wrps[i][j2]])\n",
    "            subprocess.call(command) \n",
    "            \n",
    "            labels_j2_to_j1 = torch.from_numpy(nib.load(output).get_fdata().ravel()).type('torch.LongTensor')\n",
    "            id2 = method_labels[i][j2].split('/')[-1].split('_')[0] \n",
    "            values = dicemetric(labels_j1,labels_j2_to_j1)\n",
    "            \n",
    "            for k in range(len(region_names)):\n",
    "                dice = values[k].item()\n",
    "                struct = region_names[k]\n",
    "                volume = ((labels==k).sum().item())*(0.12**3)\n",
    "                line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id2, \"target\": id1, \"dice\": dice, \"volume\": volume}  \n",
    "                list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_results_crossdice_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c655be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f9927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71c5a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-symsym\r"
     ]
    }
   ],
   "source": [
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.utils import meshgrid_ij\n",
    "\n",
    "def getDevice():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_symcompare_loss(u1, u2, warp_stn, img_size=128):\n",
    "    device = getDevice()\n",
    "    warp_stn = warp_stn.to(device)\n",
    "    image_size = (img_size, img_size, img_size)\n",
    "    mesh_points = [torch.arange(0, dim) for dim in image_size]\n",
    "    grid = torch.stack(meshgrid_ij(*mesh_points), dim=0)  # (spatial_dims, ...)\n",
    "    X = grid.to(dtype=torch.float).to(device)\n",
    "    u1X = X + u1[0,:,:,:,:]\n",
    "    u1X_x = u1X[0,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_y = u1X[1,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u1X_z = u1X[2,:,:,:].unsqueeze(0).unsqueeze(0)\n",
    "    u2u1X_x = warp_stn(u1X_x, u2)\n",
    "    u2u1X_y = warp_stn(u1X_y, u2)\n",
    "    u2u1X_z = warp_stn(u1X_z, u2)\n",
    "    u2u1X = torch.stack([u2u1X_x.squeeze(), u2u1X_y.squeeze(), u2u1X_z.squeeze()])\n",
    "    loss = torch.nn.MSELoss()\n",
    "    sym_inv_loss = loss(u2u1X, X)\n",
    "    return sym_inv_loss\n",
    "\n",
    "\n",
    "def get_sym_loss(u1, u2, weight, warp_stn, img_size=128):\n",
    "    return 0.5 * weight * (get_symcompare_loss(u1, u2, warp_stn, img_size) + get_symcompare_loss(u2, u1, warp_stn, img_size))\n",
    "\n",
    "\n",
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"SyN\",\n",
    "           \"SyN-Mask\",\n",
    "           \"SyN-Mean\",\n",
    "           \"DL-IRIS-sym\",\n",
    "           \"OP-sym\",\n",
    "           \"Pair-sym\",\n",
    "          ]\n",
    "\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "list_dict = []\n",
    "sym_warp_reflection = Warp(\"bilinear\", \"reflection\").to(getDevice())\n",
    "    \n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_fwd_wrps[i])):    \n",
    "        id1 = method_fwd_wrps[i][j].split('/')[-1].split('_')[0]  \n",
    "        multiplier = torch.tensor([-1, -1, 1]).view(1, 3, 1, 1, 1)\n",
    "        u1 = nib.load(method_fwd_wrps[i][j]).get_fdata()\n",
    "        u1 = torch.from_numpy(np.transpose(u1, (3, 4, 0, 1, 2)))\n",
    "        u1 = u1 * multiplier\n",
    "        u1 = u1.to(getDevice())\n",
    "        \n",
    "        u2 = nib.load(method_bck_wrps[i][j]).get_fdata()\n",
    "        u2 = torch.from_numpy(np.transpose(u2, (3, 4, 0, 1, 2)))\n",
    "        u2 = u2 * multiplier\n",
    "        u2 = u2.to(getDevice())\n",
    "        \n",
    "        \n",
    "        symloss = get_sym_loss(u1, u2, 1.0, sym_warp_reflection)            \n",
    "        line_dict = {\"method\": method, \"mouse\": id1, \"loss\": symloss.item()}\n",
    "        \n",
    "        list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_results_invsymloss_volume_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1fbcc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-6\r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c21fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca10d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df4004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd96426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair-nullold\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"Affine\", #\n",
    "           \"SyN\", #\n",
    "           \"SyN-Mean\", #\n",
    "           \"SyN-Mask\",#\n",
    "           \"DL-IRIS\",#\n",
    "           \"DL-GIN-3fold\",#\n",
    "           \"OP\",#\n",
    "           \"Pair\",#\n",
    "           \"Pair-aug\",#\n",
    "           \"Pair-zero\",#\n",
    "           \"Pair-null\",#\n",
    "          ]\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_affine_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mask', 'Labels', \"*_deformable.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'Gin_kfold', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda1_1.0', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda1_3', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_best_aug_nosym', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'pairwise_zero_nosym_fix', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_null', 'Labels', '*.nii.gz'))))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "kfold_csv = \"dataset3/GI3N/kfold_mapping.csv\"\n",
    "kfold_csv = pd.read_csv(kfold_csv)   \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_labels[i])):\n",
    "        if studies[i] == \"DL-GIN-3fold\":\n",
    "            fake_id = method_labels[i][j].split('/')[-1].split('_')[1] + '_' + method_labels[i][j].split('/')[-1].split('_')[2]\n",
    "            id = kfold_csv['name'][np.where(kfold_csv['fold_name'] == fake_id)[0][0]]\n",
    "        else:\n",
    "            id = method_labels[i][j].split('/')[-1].split('_')[0]    \n",
    "        labels = torch.from_numpy(nib.load(method_labels[i][j]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "        values = dicemetric(labels,map6)\n",
    "        for k in range(len(region_names)):\n",
    "            dice = values[k].item()\n",
    "            struct = region_names[k]\n",
    "            volume = ((labels==k).sum().item())*(0.12**3)\n",
    "            line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id, \"dice\": dice, \"volume\": volume}  \n",
    "            list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"isbi_results_individual_volume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d780be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b42c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f621f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5114e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PairRISmsym\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"Affine\",\n",
    "           \"SyN\",\n",
    "           \"SyN-Mask\",\n",
    "           \"SyN-Mean\",\n",
    "           #\n",
    "           \"DL-IRIS-sym\",\n",
    "           \"OP-sym\",\n",
    "           \"Pair-sym\",\n",
    "           #\n",
    "           \"DL-IRIS\",\n",
    "           \"OP\",\n",
    "           \"Pair\",\n",
    "          ]\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_affine_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mask', 'Labels', \"*_deformable.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "#\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris-sym', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_0', 'Labels', '*.nii.gz'))))\n",
    "#\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda1_1.0', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda1_3', 'Labels', '*.nii.gz'))))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0] \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j in range(len(method_labels[i])):\n",
    "        id = method_labels[i][j].split('/')[-1].split('_')[0]    \n",
    "        labels = torch.from_numpy(nib.load(method_labels[i][j]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "        values = dicemetric(labels,map6)\n",
    "        for k in range(len(region_names)):\n",
    "            dice = values[k].item()\n",
    "            struct = region_names[k]\n",
    "            volume = ((labels==k).sum().item())*(0.12**3)\n",
    "            line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id, \"dice\": dice, \"volume\": volume}  \n",
    "            list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_results_individual_volume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f27f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f82ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18a0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac256d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyN\r"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "studies = [\"SyN\",\n",
    "           \"SyN-Mask\",\n",
    "           \"SyN-Mean\",\n",
    "           \"DL-IRIS-sym\",\n",
    "           \"OP-sym\",\n",
    "           \"Pair-sym\",\n",
    "          ]\n",
    "\n",
    "regions = [\"bg\", \"hy\", \"mb\", \"hpf\", \"str\", \"ctx\", \"gp\", \"th\", \"cb\", \"olf\", \"bs\"]\n",
    "\n",
    "method_labels = []\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mask', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\"))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'dl-iris-sym', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz'))))\n",
    "method_labels.append(sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_0', 'Labels', '*.nii.gz'))))\n",
    "\n",
    "method_fwd_wrps = []\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "method_fwd_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_warp.nii.gz\"))))\n",
    "\n",
    "method_bck_wrps = []\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mask\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"dataset3\", \"GIN_Mean\", \"MRI\", \"*_warp_inverse.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"dl-iris-sym\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"lambda2_0.01\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "method_bck_wrps.append(sorted(glob(os.path.join(\"output\", \"GIN\", \"ith_lambda2_0\", \"DeformableWarp\", \"*_invwarp.nii.gz\"))))\n",
    "\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "values = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "list_dict = []\n",
    "for i in range(len(studies)):\n",
    "    method = studies[i]\n",
    "    print(method, end='\\r')\n",
    "    for j1 in range(len(method_labels[i])):    \n",
    "        labels_j1 = torch.from_numpy(nib.load(method_labels[i][j1]).get_fdata().ravel()).type('torch.LongTensor')  \n",
    "        id1 = method_labels[i][j1].split('/')[-1].split('_')[0]      \n",
    "        for j2 in range(len(method_labels[i])):  \n",
    "            output = 'temp_crossdice.nii.gz'\n",
    "            command = ['antsApplyTransforms']\n",
    "            command.extend(['-d', '3'])\n",
    "            command.extend(['-i', method_labels[i][j2]])\n",
    "            command.extend(['-r', method_labels[i][j1]])\n",
    "            command.extend(['-o', output])\n",
    "            command.extend(['-n', 'MultiLabel'])\n",
    "            command.extend(['-t', method_bck_wrps[i][j1]])\n",
    "            command.extend(['-t', method_fwd_wrps[i][j2]])\n",
    "            subprocess.call(command) \n",
    "            \n",
    "            labels_j2_to_j1 = torch.from_numpy(nib.load(output).get_fdata().ravel()).type('torch.LongTensor')\n",
    "            id2 = method_labels[i][j2].split('/')[-1].split('_')[0] \n",
    "            values = dicemetric(labels_j1,labels_j2_to_j1)\n",
    "            \n",
    "            for k in range(len(region_names)):\n",
    "                dice = values[k].item()\n",
    "                struct = region_names[k]\n",
    "                volume = ((labels==k).sum().item())*(0.12**3)\n",
    "                line_dict = {\"method\": method, \"struct\": struct, \"mouse\": id2, \"target\": id1, \"dice\": dice, \"volume\": volume}  \n",
    "                list_dict.append(line_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"sym_results_crossdice_volume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d920d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551db03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f53fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa0696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280918fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e044356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'M8876', 'type': 'MAP6', 'pairwise_null_bg': 0.9867140650749207, 'pairwise_null_hy': 0.8015897870063782, 'pairwise_null_mb': 0.6461385488510132, 'pairwise_null_hpf': 0.9055821299552917, 'pairwise_null_str': 0.877001166343689, 'pairwise_null_ctx': 0.8944650292396545, 'pairwise_null_gp': 0.5409373044967651, 'pairwise_null_th': 0.8745076656341553, 'pairwise_null_cb': 0.878031849861145, 'pairwise_null_olf': 0.6064233183860779, 'pairwise_null_bs': 0.8236436247825623}\n"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_null', 'Labels', \"*_labels.nii.gz\")))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"pairwise_null_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"pairwise_null_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06694ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'M8876', 'type': 'MAP6', 'pairwise_overfit_bg': 0.9876539707183838, 'pairwise_overfit_hy': 0.8124729990959167, 'pairwise_overfit_mb': 0.6849910616874695, 'pairwise_overfit_hpf': 0.9149973392486572, 'pairwise_overfit_str': 0.8852702975273132, 'pairwise_overfit_ctx': 0.8984541296958923, 'pairwise_overfit_gp': 0.5820398926734924, 'pairwise_overfit_th': 0.8883847594261169, 'pairwise_overfit_cb': 0.9146549701690674, 'pairwise_overfit_olf': 0.7150043845176697, 'pairwise_overfit_bs': 0.8456494212150574}\n"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_overfit', 'Labels', \"*_labels.nii.gz\")))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"pairwise_overfit_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"pairwise_overfit_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14778d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'M8876', 'type': 'MAP6', 'pairwise_zero_bg': 0.9864762425422668, 'pairwise_zero_hy': 0.7968281507492065, 'pairwise_zero_mb': 0.691172182559967, 'pairwise_zero_hpf': 0.9074633717536926, 'pairwise_zero_str': 0.8826168179512024, 'pairwise_zero_ctx': 0.8890162110328674, 'pairwise_zero_gp': 0.6039719581604004, 'pairwise_zero_th': 0.8834868669509888, 'pairwise_zero_cb': 0.9157130122184753, 'pairwise_zero_olf': 0.6983031630516052, 'pairwise_zero_bs': 0.851127564907074}\n"
     ]
    }
   ],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'pairwise_zero_nosym_fix', 'Labels', \"*_labels.nii.gz\")))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"pairwise_zero_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"pairwise_zero_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b9c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955b7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5d42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d9b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d6b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8cda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "affine_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_affine_convert.nii.gz\")))\n",
    "deep1_labels = sorted(glob(os.path.join('output', 'GIN', 'scenario1', 'Labels', '*.nii.gz')))\n",
    "deep2_labels = sorted(glob(os.path.join('output', 'GIN', 'scenario2', 'Labels', '*.nii.gz')))\n",
    "deep3_labels = sorted(glob(os.path.join('output', 'GIN', 'scenario3', 'Labels', '*.nii.gz')))\n",
    "ants_labels = sorted(glob(os.path.join('dataset3', 'GIN', 'Labels', \"*_deformable_convert.nii.gz\")))\n",
    "mean_labels = sorted(glob(os.path.join('dataset3', 'GIN_Mean', 'Labels', \"*_deformable_convert.nii.gz\")))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_affine = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_deep1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_deep2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_deep3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ants = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_mean = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ants_labels):  \n",
    "    count += 1\n",
    "    affine = torch.from_numpy(nib.load(affine_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    affine[np.where(affine > 10)] = 0\n",
    "    deep1 = torch.from_numpy(nib.load(deep1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    deep1[np.where(deep1 > 10)] = 0\n",
    "    deep2 = torch.from_numpy(nib.load(deep2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    deep2[np.where(deep2 > 10)] = 0\n",
    "    deep3 = torch.from_numpy(nib.load(deep3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    deep3[np.where(deep3 > 10)] = 0\n",
    "    ants = torch.from_numpy(nib.load(ants_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ants[np.where(ants > 10)] = 0  \n",
    "    mean = torch.from_numpy(nib.load(mean_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    mean[np.where(mean > 10)] = 0  \n",
    "\n",
    "    affine_values = dicemetric(affine,map6)\n",
    "    deep1_values = dicemetric(deep1,map6)\n",
    "    deep2_values = dicemetric(deep2,map6)\n",
    "    deep3_values = dicemetric(deep3,map6)\n",
    "    ants_values = dicemetric(ants,map6)    \n",
    "    mean_values = dicemetric(mean,map6)  \n",
    "    for j in range(len(deep1_values)):\n",
    "        values_affine[j] = affine_values[j].item()\n",
    "        values_deep1[j] = deep1_values[j].item()\n",
    "        values_deep2[j] = deep2_values[j].item()\n",
    "        values_deep3[j] = deep3_values[j].item()\n",
    "        values_ants[j] = ants_values[j].item()\n",
    "        values_mean[j] = mean_values[j].item()\n",
    "    name = ants_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    affine_dict = {\"affine_dice_\" + str(region_names[k]): values_affine[k] for k in range(len(region_names))}\n",
    "    ants_dict = {\"ants_dice_\" + str(region_names[k]): values_ants[k] for k in range(len(region_names))}\n",
    "    deep1_dict = {\"deep1_dice_\" + str(region_names[k]): values_deep1[k] for k in range(len(region_names))}\n",
    "    deep2_dict = {\"deep2_dice_\" + str(region_names[k]): values_deep2[k] for k in range(len(region_names))}\n",
    "    deep3_dict = {\"deep3_dice_\" + str(region_names[k]): values_deep3[k] for k in range(len(region_names))}\n",
    "    mean_dict = {\"antsmean_dice_\" + str(region_names[k]): values_mean[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(affine_dict)\n",
    "    ith_dict.update(ants_dict)\n",
    "    ith_dict.update(deep1_dict)\n",
    "    ith_dict.update(deep2_dict)\n",
    "    ith_dict.update(deep3_dict)\n",
    "    ith_dict.update(mean_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcdc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e39c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "l10e3_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_0.001', 'Labels', '*.nii.gz')))\n",
    "l10e2_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_0.01', 'Labels', '*.nii.gz')))\n",
    "l10e1_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_0.1', 'Labels', '*.nii.gz')))\n",
    "l10e0_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_1.0', 'Labels', '*.nii.gz')))\n",
    "l10n1_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_10', 'Labels', '*.nii.gz')))\n",
    "l10n2_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_100', 'Labels', '*.nii.gz')))\n",
    "l10n3_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda1_1000', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_l10e3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e0 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(l10e3_labels):  \n",
    "    count += 1\n",
    "    l10e3 = torch.from_numpy(nib.load(l10e3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e3[np.where(l10e3 > 10)] = 0\n",
    "    l10e2 = torch.from_numpy(nib.load(l10e2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e2[np.where(l10e2 > 10)] = 0\n",
    "    l10e1 = torch.from_numpy(nib.load(l10e1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e1[np.where(l10e1 > 10)] = 0\n",
    "    l10e0 = torch.from_numpy(nib.load(l10e0_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e0[np.where(l10e0 > 10)] = 0\n",
    "    l10n1 = torch.from_numpy(nib.load(l10n1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n1[np.where(l10n1 > 10)] = 0  \n",
    "    l10n2 = torch.from_numpy(nib.load(l10n2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n2[np.where(l10n2 > 10)] = 0  \n",
    "    l10n3 = torch.from_numpy(nib.load(l10n3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n3[np.where(l10n3 > 10)] = 0  \n",
    "\n",
    "    l10e3_values = dicemetric(l10e3,map6)\n",
    "    l10e2_values = dicemetric(l10e2,map6)\n",
    "    l10e1_values = dicemetric(l10e1,map6)\n",
    "    l10e0_values = dicemetric(l10e0,map6)\n",
    "    l10n1_values = dicemetric(l10n1,map6)    \n",
    "    l10n2_values = dicemetric(l10n2,map6)     \n",
    "    l10n3_values = dicemetric(l10n3,map6)\n",
    "    for j in range(len(l10e3_values)):\n",
    "        values_l10e3[j] = l10e3_values[j].item()\n",
    "        values_l10e2[j] = l10e2_values[j].item()\n",
    "        values_l10e1[j] = l10e1_values[j].item()\n",
    "        values_l10e0[j] = l10e0_values[j].item()\n",
    "        values_l10n1[j] = l10n1_values[j].item()\n",
    "        values_l10n2[j] = l10n2_values[j].item()\n",
    "        values_l10n3[j] = l10n3_values[j].item()\n",
    "    name = l10e3_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    l10e3_dict = {\"l10e3_dice_\" + str(region_names[k]): values_l10e3[k] for k in range(len(region_names))}\n",
    "    l10e2_dict = {\"l10e2_dice_\" + str(region_names[k]): values_l10e2[k] for k in range(len(region_names))}\n",
    "    l10e1_dict = {\"l10e1_dice_\" + str(region_names[k]): values_l10e1[k] for k in range(len(region_names))}\n",
    "    l10e0_dict = {\"l10e0_dice_\" + str(region_names[k]): values_l10e0[k] for k in range(len(region_names))}\n",
    "    l10n1_dict = {\"l10n1_dice_\" + str(region_names[k]): values_l10n1[k] for k in range(len(region_names))}\n",
    "    l10n2_dict = {\"l10n2_dice_\" + str(region_names[k]): values_l10n2[k] for k in range(len(region_names))}\n",
    "    l10n3_dict = {\"l10n3_dice_\" + str(region_names[k]): values_l10n3[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(l10e3_dict)\n",
    "    ith_dict.update(l10e2_dict)\n",
    "    ith_dict.update(l10e1_dict)\n",
    "    ith_dict.update(l10e0_dict)\n",
    "    ith_dict.update(l10n1_dict)\n",
    "    ith_dict.update(l10n2_dict)\n",
    "    ith_dict.update(l10n3_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"lambda1_gin_dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c25562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "l10e3_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.001', 'Labels', '*.nii.gz')))\n",
    "l10e2_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz')))\n",
    "l10e1_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.1', 'Labels', '*.nii.gz')))\n",
    "l10e0_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_1.0', 'Labels', '*.nii.gz')))\n",
    "l10n1_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_10', 'Labels', '*.nii.gz')))\n",
    "l10n2_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_100', 'Labels', '*.nii.gz')))\n",
    "l10n3_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_1000', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_l10e3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e0 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(l10e3_labels):  \n",
    "    count += 1\n",
    "    l10e3 = torch.from_numpy(nib.load(l10e3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e3[np.where(l10e3 > 10)] = 0\n",
    "    l10e2 = torch.from_numpy(nib.load(l10e2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e2[np.where(l10e2 > 10)] = 0\n",
    "    l10e1 = torch.from_numpy(nib.load(l10e1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e1[np.where(l10e1 > 10)] = 0\n",
    "    l10e0 = torch.from_numpy(nib.load(l10e0_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e0[np.where(l10e0 > 10)] = 0\n",
    "    l10n1 = torch.from_numpy(nib.load(l10n1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n1[np.where(l10n1 > 10)] = 0  \n",
    "    l10n2 = torch.from_numpy(nib.load(l10n2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n2[np.where(l10n2 > 10)] = 0  \n",
    "    l10n3 = torch.from_numpy(nib.load(l10n3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n3[np.where(l10n3 > 10)] = 0  \n",
    "\n",
    "    l10e3_values = dicemetric(l10e3,map6)\n",
    "    l10e2_values = dicemetric(l10e2,map6)\n",
    "    l10e1_values = dicemetric(l10e1,map6)\n",
    "    l10e0_values = dicemetric(l10e0,map6)\n",
    "    l10n1_values = dicemetric(l10n1,map6)    \n",
    "    l10n2_values = dicemetric(l10n2,map6)     \n",
    "    l10n3_values = dicemetric(l10n3,map6)\n",
    "    for j in range(len(l10e3_values)):\n",
    "        values_l10e3[j] = l10e3_values[j].item()\n",
    "        values_l10e2[j] = l10e2_values[j].item()\n",
    "        values_l10e1[j] = l10e1_values[j].item()\n",
    "        values_l10e0[j] = l10e0_values[j].item()\n",
    "        values_l10n1[j] = l10n1_values[j].item()\n",
    "        values_l10n2[j] = l10n2_values[j].item()\n",
    "        values_l10n3[j] = l10n3_values[j].item()\n",
    "    name = l10e3_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    l10e3_dict = {\"l10e3_dice_\" + str(region_names[k]): values_l10e3[k] for k in range(len(region_names))}\n",
    "    l10e2_dict = {\"l10e2_dice_\" + str(region_names[k]): values_l10e2[k] for k in range(len(region_names))}\n",
    "    l10e1_dict = {\"l10e1_dice_\" + str(region_names[k]): values_l10e1[k] for k in range(len(region_names))}\n",
    "    l10e0_dict = {\"l10e0_dice_\" + str(region_names[k]): values_l10e0[k] for k in range(len(region_names))}\n",
    "    l10n1_dict = {\"l10n1_dice_\" + str(region_names[k]): values_l10n1[k] for k in range(len(region_names))}\n",
    "    l10n2_dict = {\"l10n2_dice_\" + str(region_names[k]): values_l10n2[k] for k in range(len(region_names))}\n",
    "    l10n3_dict = {\"l10n3_dice_\" + str(region_names[k]): values_l10n3[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(l10e3_dict)\n",
    "    ith_dict.update(l10e2_dict)\n",
    "    ith_dict.update(l10e1_dict)\n",
    "    ith_dict.update(l10e0_dict)\n",
    "    ith_dict.update(l10n1_dict)\n",
    "    ith_dict.update(l10n2_dict)\n",
    "    ith_dict.update(l10n3_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"lambda2_gin_dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985699f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac7ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab958c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith_labels = sorted(glob(os.path.join('output', 'GIN', 'ith', 'Labels', '*.nii.gz')))\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith2', 'Labels', '*.nii.gz')))\n",
    "ith3_labels = sorted(glob(os.path.join('output', 'GIN', 'ith3', 'Labels', '*.nii.gz')))\n",
    "gin_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01', 'Labels', '*.nii.gz')))\n",
    "gin_noaug_labels = sorted(glob(os.path.join('output', 'GIN', 'lambda2_0.01_noaug', 'Labels', '*.nii.gz')))\n",
    "all_labels = sorted(glob(os.path.join('output', 'GIN', 'gin+feminad', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ith3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_gin = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_gin_noaug = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_all = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith_labels):  \n",
    "    count += 1\n",
    "    ith = torch.from_numpy(nib.load(ith_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith[np.where(ith > 10)] = 0\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith3 = torch.from_numpy(nib.load(ith3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith3[np.where(ith3 > 10)] = 0\n",
    "    gin = torch.from_numpy(nib.load(gin_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    gin[np.where(gin > 10)] = 0    \n",
    "    gin_noaug = torch.from_numpy(nib.load(gin_noaug_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    gin_noaug[np.where(gin_noaug > 10)] = 0\n",
    "    vall = torch.from_numpy(nib.load(all_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    vall[np.where(vall > 10)] = 0\n",
    "    \n",
    "\n",
    "    ith_values = dicemetric(ith,map6)\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    ith3_values = dicemetric(ith3,map6)\n",
    "    gin_values = dicemetric(gin,map6)\n",
    "    gin_noaug_values = dicemetric(gin_noaug,map6)\n",
    "    all_values = dicemetric(vall,map6)\n",
    "    for j in range(len(ith_values)):\n",
    "        values_ith[j] = ith_values[j].item()\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "        values_ith3[j] = ith3_values[j].item()\n",
    "        values_gin[j] = gin_values[j].item()\n",
    "        values_gin_noaug[j] = gin_noaug_values[j].item()\n",
    "        values_all[j] = all_values[j].item()\n",
    "    name = ith_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith_dict = {\"ith_dice_\" + str(region_names[k]): values_ith[k] for k in range(len(region_names))}\n",
    "    vith2_dict = {\"ith_noaug_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    vith3_dict = {\"ith_overfit_dice_\" + str(region_names[k]): values_ith3[k] for k in range(len(region_names))}\n",
    "    gin_dict = {\"gin_dice_\" + str(region_names[k]): values_gin[k] for k in range(len(region_names))}\n",
    "    gin_noaug_dict = {\"gin_noaug_dice_\" + str(region_names[k]): values_gin_noaug[k] for k in range(len(region_names))}\n",
    "    all_dict = {\"all_dice_\" + str(region_names[k]): values_all[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith_dict)\n",
    "    ith_dict.update(vith2_dict)\n",
    "    ith_dict.update(vith3_dict)\n",
    "    ith_dict.update(gin_dict)\n",
    "    ith_dict.update(gin_noaug_dict)\n",
    "    ith_dict.update(all_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"final_gin4_dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da7459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'dl-painfact', 'Labels', '*.nii.gz')))\n",
    "ith3_labels = sorted(glob(os.path.join('output', 'GIN', 'dl-painfact+op', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ith3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith3 = torch.from_numpy(nib.load(ith3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith3[np.where(ith3 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    ith3_values = dicemetric(ith3,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "        values_ith3[j] = ith3_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"dl-painfact_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    vith3_dict = {\"dl-painfact+op_dice_\" + str(region_names[k]): values_ith3[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    ith_dict.update(vith3_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"final_painfact_gin_dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693df0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'gin+iris', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"gin+iris_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"gin+iris_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a38a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b33dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a15ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "l10e3_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_6', 'Labels', '*.nii.gz')))\n",
    "l10e2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_5', 'Labels', '*.nii.gz')))\n",
    "l10e1_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_4', 'Labels', '*.nii.gz')))\n",
    "l10e0_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_3', 'Labels', '*.nii.gz')))\n",
    "l10n1_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_2', 'Labels', '*.nii.gz')))\n",
    "l10n2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_1', 'Labels', '*.nii.gz')))\n",
    "l10n3_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_lambda2_0', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_l10e3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10e0 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_l10n3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(l10e3_labels):  \n",
    "    count += 1\n",
    "    l10e3 = torch.from_numpy(nib.load(l10e3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e3[np.where(l10e3 > 10)] = 0\n",
    "    l10e2 = torch.from_numpy(nib.load(l10e2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e2[np.where(l10e2 > 10)] = 0\n",
    "    l10e1 = torch.from_numpy(nib.load(l10e1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e1[np.where(l10e1 > 10)] = 0\n",
    "    l10e0 = torch.from_numpy(nib.load(l10e0_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10e0[np.where(l10e0 > 10)] = 0\n",
    "    l10n1 = torch.from_numpy(nib.load(l10n1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n1[np.where(l10n1 > 10)] = 0  \n",
    "    l10n2 = torch.from_numpy(nib.load(l10n2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n2[np.where(l10n2 > 10)] = 0  \n",
    "    l10n3 = torch.from_numpy(nib.load(l10n3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    l10n3[np.where(l10n3 > 10)] = 0  \n",
    "\n",
    "    l10e3_values = dicemetric(l10e3,map6)\n",
    "    l10e2_values = dicemetric(l10e2,map6)\n",
    "    l10e1_values = dicemetric(l10e1,map6)\n",
    "    l10e0_values = dicemetric(l10e0,map6)\n",
    "    l10n1_values = dicemetric(l10n1,map6)    \n",
    "    l10n2_values = dicemetric(l10n2,map6)     \n",
    "    l10n3_values = dicemetric(l10n3,map6)\n",
    "    for j in range(len(l10e3_values)):\n",
    "        values_l10e3[j] = l10e3_values[j].item()\n",
    "        values_l10e2[j] = l10e2_values[j].item()\n",
    "        values_l10e1[j] = l10e1_values[j].item()\n",
    "        values_l10e0[j] = l10e0_values[j].item()\n",
    "        values_l10n1[j] = l10n1_values[j].item()\n",
    "        values_l10n2[j] = l10n2_values[j].item()\n",
    "        values_l10n3[j] = l10n3_values[j].item()\n",
    "    name = l10e3_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    l10e3_dict = {\"l10e3_dice_\" + str(region_names[k]): values_l10e3[k] for k in range(len(region_names))}\n",
    "    l10e2_dict = {\"l10e2_dice_\" + str(region_names[k]): values_l10e2[k] for k in range(len(region_names))}\n",
    "    l10e1_dict = {\"l10e1_dice_\" + str(region_names[k]): values_l10e1[k] for k in range(len(region_names))}\n",
    "    l10e0_dict = {\"l10e0_dice_\" + str(region_names[k]): values_l10e0[k] for k in range(len(region_names))}\n",
    "    l10n1_dict = {\"l10n1_dice_\" + str(region_names[k]): values_l10n1[k] for k in range(len(region_names))}\n",
    "    l10n2_dict = {\"l10n2_dice_\" + str(region_names[k]): values_l10n2[k] for k in range(len(region_names))}\n",
    "    l10n3_dict = {\"l10n3_dice_\" + str(region_names[k]): values_l10n3[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(l10e3_dict)\n",
    "    ith_dict.update(l10e2_dict)\n",
    "    ith_dict.update(l10e1_dict)\n",
    "    ith_dict.update(l10e0_dict)\n",
    "    ith_dict.update(l10n1_dict)\n",
    "    ith_dict.update(l10n2_dict)\n",
    "    ith_dict.update(l10n3_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"lambda2_ithgin_dice_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885e5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_zero', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"gin+iris_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"ith_zero_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a52f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith1_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_aug', 'Labels', '*.nii.gz')))\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_noaug', 'Labels', '*.nii.gz')))\n",
    "ith3_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_overfit', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith1 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "values_ith3 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith1_labels):  \n",
    "    count += 1\n",
    "    ith1 = torch.from_numpy(nib.load(ith1_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith1[np.where(ith1 > 10)] = 0\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith3 = torch.from_numpy(nib.load(ith3_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith3[np.where(ith3 > 10)] = 0   \n",
    "\n",
    "    ith1_values = dicemetric(ith1,map6)\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    ith3_values = dicemetric(ith3,map6)\n",
    "    \n",
    "    for j in range(len(ith1_values)):\n",
    "        values_ith1[j] = ith1_values[j].item()\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "        values_ith3[j] = ith3_values[j].item()\n",
    "        \n",
    "    name = ith1_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith1_dict = {\"ith_aug_dice_\" + str(region_names[k]): values_ith1[k] for k in range(len(region_names))}\n",
    "    vith2_dict = {\"ith_noaug_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    vith3_dict = {\"ith_overfit_dice_\" + str(region_names[k]): values_ith3[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith1_dict)\n",
    "    ith_dict.update(vith2_dict)\n",
    "    ith_dict.update(vith3_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"ith_new_afterfix_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a43259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db358ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382189a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_best_aug', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"ith_best_aug_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"ith_best_aug_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_mask = \"dataset3/Atlas/P56_Annotation_128_norm_id_mask.nii.gz\"\n",
    "atlas_labels = \"atlas_gin_map6.nii.gz\"\n",
    "\n",
    "ith2_labels = sorted(glob(os.path.join('output', 'GIN', 'ith_best_aug_nosym', 'Labels', '*.nii.gz')))\n",
    "\n",
    "dicemetric = torchmetrics.Dice(average=None, mdmc_average='global', num_classes=11)\n",
    "\n",
    "values_ith2 = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mapping_csv = \"dataset3/GIN/labels_mapping.csv\"\n",
    "data = pd.read_csv(mapping_csv)\n",
    "    \n",
    "map6 = torch.from_numpy(nib.load(atlas_labels).get_fdata().ravel()).type('torch.LongTensor')\n",
    "count = 0\n",
    "\n",
    "list_dict = []\n",
    "\n",
    "for i, _ in enumerate(ith2_labels):  \n",
    "    count += 1\n",
    "    ith2 = torch.from_numpy(nib.load(ith2_labels[i]).get_fdata().ravel()).type('torch.LongTensor')\n",
    "    ith2[np.where(ith2 > 10)] = 0\n",
    "    ith2_values = dicemetric(ith2,map6)\n",
    "    for j in range(len(ith2_values)):\n",
    "        values_ith2[j] = ith2_values[j].item()\n",
    "    name = ith2_labels[i].split('/')[-1].split('_')[0]    \n",
    "    datatype = \"MAP6\" if \"M\" in name else \"SVBP\"    \n",
    "    vith2_dict = {\"ith_best_aug_nosym_dice_\" + str(region_names[k]): values_ith2[k] for k in range(len(region_names))}\n",
    "    ith_dict = {\"name\": name, \"type\": datatype}\n",
    "    ith_dict.update(vith2_dict)\n",
    "    list_dict.append(ith_dict)\n",
    "print(ith_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df.to_csv(\"ith_best_aug_nosym_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9909b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
