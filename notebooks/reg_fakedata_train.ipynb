{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import AsDiscrete, MaskIntensity, RandAffine, Affine\n",
    "from monai.utils import set_determinism\n",
    "from monai.losses import LocalNormalizedCrossCorrelationLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "import utils_parser\n",
    "from reg_data import getRegistrationDataset\n",
    "from reg_model import getRegistrationModel\n",
    "from utils import compute_mean_dice, getAdamOptimizer, getReducePlateauScheduler, loadExistingModel, getDevice\n",
    "from utils import print_model_output, print_weights, add_weights_to_name, compute_landmarks_distance_local\n",
    "from loss import get_deformable_registration_loss_from_weights, get_affine_registration_loss_from_weights, jacobian_loss, get_jacobian, antifolding_loss, JacobianDet\n",
    "from models import TrilinearLocalNet\n",
    "from torchinfo import summary\n",
    "from miseval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Train 3D mouse brain registration model.\")\n",
    "parser.add_argument(\"-lr\", \"--learningrate\", type=float, default=0.001, help=\"Specify learning rate.\")\n",
    "parser.add_argument(\"-p\", \"--patience\", type=int, default=20, help=\"Specify patience for LR Plateau.\")\n",
    "parser.add_argument(\"-b\", \"--batchsize\", type=int, default=1, help=\"Batch size for training\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=500, help=\"Max epochs for training\")\n",
    "parser.add_argument(\"-o\", \"--output\", help=\"Model name for save\")\n",
    "parser.add_argument(\"-d\", \"--dataset\", default='IRIS', help=\"Dataset name for training.\")\n",
    "parser.add_argument(\"-ft\", \"--finetuning\", help=\"Load existing model for finetuning.\")\n",
    "parser.add_argument(\"-ct\", \"--continuetraining\", help=\"Load existing model to continue training.\")\n",
    "parser.add_argument(\"-pt\", \"--pretraining\", help=\"Load existing model for affine registration.\")\n",
    "parser.add_argument(\"-t\", \"--type\", type=str, help=\"Specify affine/deformable/local registration\")\n",
    "parser.add_argument(\"-a\", \"--atlas\", action='store_true', help=\"Perform to-atlas registration instead of paired registration\")\n",
    "parser.add_argument(\"-m\", \"--mask\", action='store_true', help=\"Skullstrip dataset if available\")\n",
    "parser.add_argument(\"-w\", \"--weights\", nargs='+', type=float, default=[1.0, 0, 2.0], help=\"Loss weights for 1) ImageLoss 2) LabelLoss 3) DDF. Default : [1,1,1]\")\n",
    "parser.add_argument(\"-newmodel\", \"--newmodel\", action='store_true', help=\"True: Depth 5 Channels 32; False: Depth 4 Channels 16\")\n",
    "parser.add_argument(\"-validfeminad\", \"--validfeminad\", action='store_true', help=\"True: Validate on Feminad with Landmarks\")\n",
    "parser.add_argument(\"-freeze\", \"--freeze\", type=int, default=0, help=\"Freeze Xth layer\")\n",
    "parser.add_argument(\"-cycleconsistenttraining\", \"--cycleconsistenttraining\", action='store_true', help=\"UseCycleConsistentTraining\")\n",
    "parser.add_argument(\"-affineconsistenttraining\", \"--affineconsistenttraining\", action='store_true', help=\"UseAffineConsistentTraining\")\n",
    "parser.add_argument(\"-jacobianloss\", \"--jacobianloss\", action='store_true', help=\"UseJacobianDetLoss\")\n",
    "parser.add_argument(\"-antifoldingloss\", \"--antifoldingloss\", action='store_true', help=\"UseAntiFoldingLoss\")\n",
    "parser.add_argument(\"-ddf\", \"--ddf\", action='store_true', help=\"Use DDF instead of DVF2DDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaeb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"fakedata\"\n",
    "dataset = \"fakedata\"\n",
    "ft = None\n",
    "ct = None\n",
    "batchsize = 1\n",
    "max_epochs = 500\n",
    "lr = 0.001\n",
    "patience\n",
    "weights\n",
    "registration_type\n",
    "atlas\n",
    "mask\n",
    "pt\n",
    "newmodel\n",
    "validfeminad\n",
    "freeze\n",
    "cycle_consistent_training\n",
    "use_jacobian_loss\n",
    "affine_consistent_training\n",
    "use_antifolding_loss\n",
    "use_ddf\n",
    "\n",
    "\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "modelname = add_weights_to_name(modelname, weights)\n",
    "print_model_output(modelname)\n",
    "set_determinism(seed=0)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "device = getDevice()\n",
    "\n",
    "if newmodel:\n",
    "    channels = 32\n",
    "    extract = [0, 1, 2, 3, 4]\n",
    "else:\n",
    "    channels = 16\n",
    "    extract = [0, 1, 2, 3]\n",
    "model = getRegistrationModel(registration_type, img_size=128, pretrain_model=pt,\n",
    "                                 channels=channels, extract=extract, use_ddf=use_ddf)\n",
    "\n",
    "optimizer = getAdamOptimizer(model, lr)\n",
    "scheduler = getReducePlateauScheduler(optimizer, factor=0.5, patience=20)\n",
    "weights = loadExistingModel(model, optimizer, ft, ct, weights=weights, registration=True)\n",
    "print_weights(weights)\n",
    "\n",
    "dataloaders, size = getRegistrationDataset(dataset=dataset,\n",
    "                                           batch=batchsize,\n",
    "                                           training=True,\n",
    "                                           augment=True,\n",
    "                                           eval_augment=False,\n",
    "                                           atlas=atlas,\n",
    "                                           mask=mask,\n",
    "                                           validfeminad=validfeminad,\n",
    "                                           )\n",
    "\n",
    "best_loss = np.inf\n",
    "best_epoch = -1\n",
    "\n",
    "writer = SummaryWriter(comment='_'+modelname)\n",
    "sizelol = len(dataloaders[\"train\"])\n",
    "print(sizelol)\n",
    "\n",
    "reduceLReveryepochs = False\n",
    "\n",
    "if freeze != 0:\n",
    "    print(\"=> Freezing model\")\n",
    "    for name, p in model.named_parameters():\n",
    "        p.requires_grad = False\n",
    "for epoch in range(-1, max_epochs):\n",
    "#for epoch in range(max_epochs):\n",
    "    if freeze == 1:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 2:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 3:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 4:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.0.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 5:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.3.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 6:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.0.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.3.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if freeze == 7:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"encode_convs.1.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.2.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"encode_convs.3.\" in name:\n",
    "                p.requires_grad = True\n",
    "            if \"bottom_block.\" in name:\n",
    "                p.requires_grad = True\n",
    "    if reduceLReveryepochs:\n",
    "        if epoch != 0 and epoch % 400 == 0:\n",
    "            weights = [weights[0], 0, weights[2]/2]\n",
    "            print(\"New weights: \" + str(weights))\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "\n",
    "    train_loss, train_metric, train_dice, train_lbl_loss, train_img_loss, train_ddf_loss = 0, 0, 0, 0, 0, 0\n",
    "    valid_loss, valid_metric, valid_dice, valid_lbl_loss, valid_img_loss, valid_ddf_loss = 0, 0, 0, 0, 0, 0\n",
    "    if cycle_consistent_training:\n",
    "        train_cycle_loss, valid_cycle_loss = 0, 0\n",
    "    if use_jacobian_loss:\n",
    "        train_jcb_loss, valid_jcb_loss = 0, 0\n",
    "    if affine_consistent_training:\n",
    "        train_aff_loss, valid_aff_loss = 0, 0\n",
    "    if use_antifolding_loss:\n",
    "        train_fold_loss, valid_fold_loss = 0, 0\n",
    "\n",
    "    for phase in ['train', 'valid']:\n",
    "        if epoch == -1 and phase == 'train':\n",
    "            continue\n",
    "        if pt is None:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            elif phase == 'valid':\n",
    "                model.eval()\n",
    "        else:\n",
    "            for param in model.globalnet.parameters():\n",
    "                param.requires_grad = False\n",
    "            if phase == 'train':\n",
    "                model.globalnet.eval()\n",
    "                model.localnet.train()\n",
    "            elif phase == 'valid':\n",
    "                model.globalnet.eval()\n",
    "                model.localnet.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        if cycle_consistent_training:\n",
    "            running_cycle_loss = 0.0\n",
    "        if use_jacobian_loss:\n",
    "            running_jcb_loss = 0.0\n",
    "        if affine_consistent_training:\n",
    "            running_aff_loss = 0.0\n",
    "        if use_antifolding_loss:\n",
    "            running_fold_loss = 0.0\n",
    "        running_metric = 0.0\n",
    "        running_dice = 0.0\n",
    "        running_img_loss = 0.0\n",
    "        running_lbl_loss = 0.0\n",
    "        running_ddf_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(dataloaders[phase]):\n",
    "            if i >= sizelol:\n",
    "                break\n",
    "\n",
    "            print(i, end='\\r')\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                if registration_type.lower() == 'affine' or registration_type.lower() == 'local':\n",
    "                    ddf, pred_image, pred_label, dvf = model(data)\n",
    "                elif registration_type.lower() == 'deformable':\n",
    "                    affine_ddf, ddf, pred_image, pred_label, affine_image, affine_label = model(data)\n",
    "                    #affine_image = affine_image.to(device, non_blocking=True)\n",
    "                    #affine_label = affine_label.to(device, non_blocking=True)\n",
    "                    #affine_mask = AsDiscrete(threshold=0.5)(affine_label)\n",
    "                    #affine_image_masked = MaskIntensity(mask_data=affine_mask)(affine_image)\n",
    "\n",
    "                pred_image = pred_image.to(device, non_blocking=True)\n",
    "                pred_label = pred_label.to(device, non_blocking=True)\n",
    "                pred_mask = AsDiscrete(threshold=0.5)(pred_label)\n",
    "                pred_image_masked = MaskIntensity(mask_data=pred_mask)(pred_image)\n",
    "\n",
    "                fixed_image = data['fixed_image'].to(device, non_blocking=True)\n",
    "                fixed_label = data['fixed_label'].to(device, non_blocking=True)\n",
    "                fixed_mask = AsDiscrete(threshold=0.5)(fixed_label)\n",
    "                fixed_image_masked = MaskIntensity(mask_data=fixed_mask)(fixed_image)\n",
    "\n",
    "                if \"neatin\" in dataset:\n",
    "                    fixed_regions = data['fixed_regions'].to(device, non_blocking=True)\n",
    "                    fixed_regions_np = fixed_regions.cpu().detach().numpy().squeeze()\n",
    "                    moving_regions = data['moving_regions'].to(device, dtype=torch.float, non_blocking=True)\n",
    "                    pred_regions = model.warp_nearest(moving_regions, ddf)\n",
    "                    pred_regions_np = pred_regions.cpu().detach().numpy().squeeze()\n",
    "\n",
    "                if registration_type.lower() == 'affine':\n",
    "                    img_loss, lbl_loss, ddf_loss = get_affine_registration_loss_from_weights(pred_image_masked,\n",
    "                                                                                             pred_mask,\n",
    "                                                                                             fixed_image_masked,\n",
    "                                                                                             fixed_mask,\n",
    "                                                                                             weights)\n",
    "                    loss = img_loss + lbl_loss\n",
    "                elif registration_type.lower() == 'deformable' or registration_type.lower() == 'local':\n",
    "                    if use_ddf:\n",
    "                        img_loss, lbl_loss, ddf_loss = get_deformable_registration_loss_from_weights(pred_image_masked,\n",
    "                                                                                                     pred_mask,\n",
    "                                                                                                     fixed_image_masked,\n",
    "                                                                                                     fixed_mask,\n",
    "                                                                                                     ddf,\n",
    "                                                                                                     weights)\n",
    "                    else:\n",
    "                        img_loss, lbl_loss, ddf_loss = get_deformable_registration_loss_from_weights(pred_image_masked,\n",
    "                                                                                                     pred_mask,\n",
    "                                                                                                     fixed_image_masked,\n",
    "                                                                                                     fixed_mask,\n",
    "                                                                                                     dvf,\n",
    "                                                                                                     weights)\n",
    "\n",
    "                    loss = img_loss + lbl_loss + ddf_loss\n",
    "                    if use_jacobian_loss:\n",
    "                        jcb_loss = jacobian_loss(ddf) / (128*128*128)\n",
    "                        loss = loss + jcb_loss\n",
    "                    if use_antifolding_loss:\n",
    "                        fold_loss = antifolding_loss(ddf)\n",
    "                        loss = loss + fold_loss\n",
    "\n",
    "                if cycle_consistent_training and not affine_consistent_training:\n",
    "                    cycle_data = {\n",
    "                        \"fixed_image\": data[\"moving_image\"],\n",
    "                        \"fixed_label\": data[\"moving_label\"],\n",
    "                        \"moving_image\": pred_image,\n",
    "                        \"moving_label\": pred_label,\n",
    "                    }\n",
    "                    if registration_type.lower() == 'local':\n",
    "                        cycle_ddf, cycle_pred_image, cycle_pred_label, cycle_dvf = model(cycle_data)\n",
    "                        cycle_pred_image = cycle_pred_image.to(device, non_blocking=True)\n",
    "                        cycle_pred_label = cycle_pred_label.to(device, non_blocking=True)\n",
    "                        cycle_pred_mask = AsDiscrete(threshold=0.5)(cycle_pred_label)\n",
    "\n",
    "                        cycle_fixed_image = data[\"moving_image\"].to(device, non_blocking=True)\n",
    "                        cycle_fixed_label = data[\"moving_label\"].to(device, non_blocking=True)\n",
    "                        cycle_fixed_mask = AsDiscrete(threshold=0.5)(cycle_fixed_label)\n",
    "\n",
    "                        if use_ddf:\n",
    "                            cycle_img_loss, cycle_lbl_loss, cycle_ddf_loss = get_deformable_registration_loss_from_weights(cycle_pred_image,\n",
    "                                                                                                     cycle_pred_mask,\n",
    "                                                                                                     cycle_fixed_image,\n",
    "                                                                                                     cycle_fixed_mask,\n",
    "                                                                                                     cycle_ddf,\n",
    "                                                                                                     weights)\n",
    "                        else:\n",
    "                            cycle_img_loss, cycle_lbl_loss, cycle_ddf_loss = get_deformable_registration_loss_from_weights(cycle_pred_image,\n",
    "                                                                                                     cycle_pred_mask,\n",
    "                                                                                                     cycle_fixed_image,\n",
    "                                                                                                     cycle_fixed_mask,\n",
    "                                                                                                     cycle_dvf,\n",
    "                                                                                                     weights)\n",
    "                        cycle_loss = cycle_img_loss + cycle_lbl_loss + cycle_ddf_loss\n",
    "                        if use_jacobian_loss:\n",
    "                            cycle_jcb_loss = jacobian_loss(cycle_ddf) / (128*128*128)\n",
    "                            cycle_loss = cycle_loss + cycle_jcb_loss\n",
    "                        if use_antifolding_loss:\n",
    "                            cycle_fold_loss = antifolding_loss(cycle_ddf)\n",
    "                            cycle_loss = cycle_loss + cycle_fold_loss\n",
    "                        loss = loss + cycle_loss\n",
    "                if not cycle_consistent_training and affine_consistent_training:\n",
    "                    randaffine_transform = RandAffine(\n",
    "                        mode='bilinear',\n",
    "                        prob=1.0,\n",
    "                        rotate_range=(np.pi/16, np.pi/16, np.pi/16),\n",
    "                        scale_range=(0.05, 0.05, 0.05),\n",
    "                        translate_range=(5, 5, 5),\n",
    "                    )\n",
    "                    randaffine_moving_image = randaffine_transform(data[\"moving_image\"][0, :, :, :, :]).unsqueeze(0)\n",
    "                    randaffine_matrix = randaffine_transform.rand_affine_grid.get_transformation_matrix()\n",
    "                    randaffine_transform_nearest = Affine(\n",
    "                        mode='nearest',\n",
    "                        affine=randaffine_matrix\n",
    "                    )\n",
    "                    randaffine_moving_label, _ = randaffine_transform_nearest(data[\"moving_label\"][0, :, :, :, :])\n",
    "                    randaffine_moving_label = randaffine_moving_label.unsqueeze(0)\n",
    "                    randaffine_data = {\n",
    "                        \"fixed_image\": fixed_image,\n",
    "                        \"fixed_label\": fixed_label,\n",
    "                        \"moving_image\": randaffine_moving_image,\n",
    "                        \"moving_label\": randaffine_moving_label,\n",
    "                    }\n",
    "\n",
    "                    if registration_type.lower() == 'local':\n",
    "                        randaffine_ddf, randaffine_pred_image, randaffine_pred_label, _ = model(randaffine_data)\n",
    "\n",
    "                        # u1 - A o u2 = 0\n",
    "                        # => pred1 - pred2 = 0\n",
    "                        randaffine_pred_image = randaffine_pred_image.to(device, non_blocking=True)\n",
    "                        randaffine_pred_label = randaffine_pred_label.to(device, non_blocking=True)\n",
    "\n",
    "                        aff_loss = LocalNormalizedCrossCorrelationLoss()(pred_image, randaffine_pred_image)\n",
    "                        loss = loss + aff_loss\n",
    "\n",
    "\n",
    "                dice_metric = compute_mean_dice(pred_mask, fixed_mask)\n",
    "                if registration_type.lower() == 'local' and phase == 'valid' and (validfeminad or \"feminad\" in dataset):\n",
    "                    #metric = np.mean(compute_landmarks_distance_local(ddf, data))\n",
    "                    metric = np.mean(compute_landmarks_distance_local(ddf, data)[1:])\n",
    "                elif registration_type.lower() == 'local' and \"neatin\" in dataset:\n",
    "                    metric = evaluate(fixed_regions_np, pred_regions_np, metric=\"DSC\", multi_class=True, n_classes=41)\n",
    "                    metric = np.mean(metric)\n",
    "                else:\n",
    "                    metric = torch.zeros(1)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # scaler.scale(loss).backward()\n",
    "                    # scaler.step(optimizer)\n",
    "                    # scaler.update()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * fixed_image.size(0)\n",
    "            if cycle_consistent_training:\n",
    "                running_cycle_loss += cycle_loss.item() * fixed_image.size(0)\n",
    "            if use_jacobian_loss:\n",
    "                running_jcb_loss += jcb_loss.item() * fixed_image.size(0)\n",
    "            if affine_consistent_training:\n",
    "                running_aff_loss += aff_loss.item() * fixed_image.size(0)\n",
    "            if use_antifolding_loss:\n",
    "                running_fold_loss += fold_loss.item() * fixed_image.size(0)\n",
    "            running_metric += metric.item() * fixed_image.size(0)\n",
    "            running_dice += dice_metric.item() * fixed_image.size(0)\n",
    "            running_img_loss += img_loss.item() * fixed_image.size(0)\n",
    "            running_lbl_loss += lbl_loss.item() * fixed_image.size(0)\n",
    "            running_ddf_loss += ddf_loss.item() * fixed_image.size(0)\n",
    "\n",
    "\n",
    "        running_loss /= sizelol\n",
    "        if cycle_consistent_training:\n",
    "            running_cycle_loss /= sizelol\n",
    "        if use_jacobian_loss:\n",
    "            running_jcb_loss /= sizelol\n",
    "        if affine_consistent_training:\n",
    "            running_aff_loss /= sizelol\n",
    "        if use_antifolding_loss:\n",
    "            running_fold_loss /= sizelol\n",
    "        running_metric /= sizelol\n",
    "        running_dice /= sizelol\n",
    "        running_img_loss /= sizelol\n",
    "        running_lbl_loss /= sizelol\n",
    "        running_ddf_loss /= sizelol\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_loss, train_metric, train_img_loss, train_lbl_loss, train_ddf_loss = (\n",
    "                running_loss, running_metric, running_img_loss, running_lbl_loss, running_ddf_loss)\n",
    "            train_dice = running_dice\n",
    "            if cycle_consistent_training:\n",
    "                train_cycle_loss = running_cycle_loss\n",
    "            if use_jacobian_loss:\n",
    "                train_jcb_loss = running_jcb_loss\n",
    "            if affine_consistent_training:\n",
    "                train_aff_loss = running_aff_loss\n",
    "            if use_antifolding_loss:\n",
    "                train_fold_loss = running_fold_loss\n",
    "        elif phase == 'valid':\n",
    "            valid_loss, valid_metric, valid_img_loss, valid_lbl_loss, valid_ddf_loss = (\n",
    "                running_loss, running_metric, running_img_loss, running_lbl_loss, running_ddf_loss)\n",
    "            valid_dice = running_dice\n",
    "            if cycle_consistent_training:\n",
    "                valid_cycle_loss = running_cycle_loss\n",
    "            if use_jacobian_loss:\n",
    "                valid_jcb_loss = running_jcb_loss\n",
    "            if affine_consistent_training:\n",
    "                valid_aff_loss = running_aff_loss\n",
    "            if use_antifolding_loss:\n",
    "                valid_fold_loss = running_fold_loss\n",
    "\n",
    "        outmessage = \"{}: loss: {:.4f} - metric: {:.4f} -- img: {:.4f}, lbl: {:.4f}, ddf: {:.4f}\".format(\n",
    "                phase, running_loss, running_metric, running_img_loss, running_lbl_loss, running_ddf_loss)\n",
    "        if cycle_consistent_training:\n",
    "            outmessage += \" -- cycle: {:.4f}\".format(running_cycle_loss)\n",
    "        if use_jacobian_loss:\n",
    "            outmessage += \" -- jac: {:.4f}\".format(running_jcb_loss)\n",
    "        if affine_consistent_training:\n",
    "            outmessage += \" -- aff: {:.4f}\".format(running_aff_loss)\n",
    "        if use_antifolding_loss:\n",
    "            outmessage += \" -- fold: {:.4f}\".format(running_fold_loss)\n",
    "        outmessage += \" -- dice: {:.4f}\".format(running_dice)\n",
    "        print(outmessage)\n",
    "\n",
    "        if (phase == 'valid' and not validfeminad) or (phase == 'train' and validfeminad):\n",
    "            #scheduler.step(running_loss)\n",
    "            if running_loss < best_loss:\n",
    "                best_loss = running_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'weights': weights,\n",
    "                    'epoch': epoch,\n",
    "                    'lr': lr,\n",
    "                    },\n",
    "                    './models/' + modelname\n",
    "                )\n",
    "                print(\n",
    "                    \"best loss {:.4f} at epoch {}\".format(\n",
    "                        best_loss, best_epoch\n",
    "                    )\n",
    "                )\n",
    "        #if epoch % 25 == 0 and epoch > 0:\n",
    "        #    torch.save({\n",
    "        #        'model_state_dict': model.state_dict(),\n",
    "        #        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        #        'weights': weights,\n",
    "        #        'epoch': epoch,\n",
    "        #        'lr': lr,\n",
    "        #        },\n",
    "        #        './models/' + modelname.split('.pth')[0] + '_epoch' + str(epoch) + '.pth'\n",
    "        #    )\n",
    "    writer.add_scalars('epoch_loss', {\n",
    "        'train': train_loss,\n",
    "        'valid': valid_loss,\n",
    "    }, epoch + 1)\n",
    "    writer.add_scalars('epoch_metric', {\n",
    "        'train': train_metric,\n",
    "        'valid': valid_metric,\n",
    "    }, epoch + 1)\n",
    "    writer.add_scalars('epoch_dice', {\n",
    "        'train': train_dice,\n",
    "        'valid': valid_dice,\n",
    "    }, epoch + 1)\n",
    "    writer.add_scalars('epoch_lbl_loss', {\n",
    "        'train': train_lbl_loss,\n",
    "        'valid': valid_lbl_loss,\n",
    "    }, epoch + 1)\n",
    "    writer.add_scalars('epoch_img_loss', {\n",
    "        'train': train_img_loss,\n",
    "        'valid': valid_img_loss,\n",
    "    }, epoch + 1)\n",
    "    writer.add_scalars('epoch_ddf_loss', {\n",
    "        'train': train_ddf_loss,\n",
    "        'valid': valid_ddf_loss,\n",
    "    }, epoch + 1)\n",
    "    if cycle_consistent_training:\n",
    "        writer.add_scalars('epoch_cycle_loss', {\n",
    "            'train': train_cycle_loss,\n",
    "            'valid': valid_cycle_loss,\n",
    "        }, epoch + 1)\n",
    "    if use_jacobian_loss:\n",
    "        writer.add_scalars('epoch_jcb_loss', {\n",
    "            'train': train_jcb_loss,\n",
    "            'valid': valid_jcb_loss,\n",
    "        }, epoch + 1)\n",
    "    if affine_consistent_training:\n",
    "        writer.add_scalars('epoch_aff_loss', {\n",
    "            'train': train_aff_loss,\n",
    "            'valid': valid_aff_loss,\n",
    "        }, epoch + 1)\n",
    "    if use_antifolding_loss:\n",
    "        writer.add_scalars('epoch_fold_loss', {\n",
    "            'train': train_fold_loss,\n",
    "            'valid': valid_fold_loss,\n",
    "        }, epoch + 1)\n",
    "\n",
    "print(f\"train completed, \"\n",
    "      f\"best_loss: {best_loss:.4f}  \"\n",
    "      f\"at epoch: {best_epoch}\")\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
