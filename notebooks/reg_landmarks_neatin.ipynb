{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c0869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import AsDiscrete, MaskIntensity\n",
    "from monai.utils import set_determinism\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "import utils_parser\n",
    "from reg_data import getRegistrationDataset\n",
    "from reg_model import getRegistrationModel\n",
    "from utils import compute_mean_dice, getAdamOptimizer, getReducePlateauScheduler, loadExistingModel, getDevice, compute_mean_dice\n",
    "from utils import print_model_output, print_weights, add_weights_to_name, compute_landmarks_distance_local, compute_csv_distance\n",
    "from loss import get_deformable_registration_loss_from_weights, get_affine_registration_loss_from_weights\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import monai\n",
    "import torchinfo\n",
    "from miseval import evaluate\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c1e213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Using Neatin affine registered dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 43996.20it/s]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 74455.10it/s]\n",
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 84260.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99727056 0.86486067 0.58845492 0.84394648 0.4715059  0.74089494\n",
      " 0.63118029 0.8997552  0.91591427 0.81402929 0.61947485 0.85406698\n",
      " 0.8056509  0.70263117 0.88513144 0.80211086 0.84504462 0.91612041\n",
      " 0.79309199 0.83149811 0.58433839 0.84687756 1.         0.77410761\n",
      " 0.40787836 0.59477173 0.54910177 0.87722295 0.90913353 0.79511465\n",
      " 1.         0.83446216 0.8135662  0.66164304 0.86709526 0.75799324\n",
      " 0.82213567 1.         0.79567642 0.80789283 0.4927063 ]\n",
      "0.7808378420205065\n",
      "neatin-1.1-continue\n",
      "Loss: loss: 0.2422\n",
      "Labels: Dice: 0.9670 / Haussdorf: 23.4120 / IoU: 0.9362 / Sens: 0.9789 / Spec: 0.9961\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "atlas_name = \"dataset2/Atlas/Identity_Neatin_MRI_A9.nii.gz\"\n",
    "atlas_affine = nib.load(atlas_name).affine\n",
    "atlas_header = nib.load(atlas_name).header \n",
    "z = 0\n",
    "names = [\n",
    "        #\"neatin-1.2\",\n",
    "        \"neatin-1.1-continue\",\n",
    "        #\"neatin-1.1-masked\",\n",
    "        #\"neatin-finetunepainfact\",\n",
    "        ]\n",
    "for modelname in [\n",
    "    #\"neatin_scenario1_1.0-0.0-2.0.pth\",\n",
    "    \"neatin_scenario1_continue_1.0-0.0-1.0.pth\",\n",
    "    #\"neatin_scenario1_maskedloss_1.0-0.0-1.0.pth\",\n",
    "    #\"neatin_scenario3_1.0-0.0-1.0.pth\",\n",
    "           \n",
    "                 ]:\n",
    "    dataset = \"neatinaffine\"\n",
    "    batchsize = 1\n",
    "    registration_type = \"local\"\n",
    "    atlas=True\n",
    "    mask=False\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    set_determinism(seed=0)\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    device = getDevice()\n",
    "    \n",
    "    \n",
    "    if \"ddf\" in modelname:\n",
    "        use_ddf = True\n",
    "    else:\n",
    "        use_ddf = False\n",
    "    model = getRegistrationModel(registration_type, img_size=128, channels=32, extract=[0,1,2,3,4], use_ddf=use_ddf)\n",
    "    weights = loadExistingModel(model, None, ft=modelname, registration=True)\n",
    "    model.eval()\n",
    "\n",
    "    dataloaders, size = getRegistrationDataset(dataset=dataset,\n",
    "                                               batch=batchsize,\n",
    "                                               training=False,\n",
    "                                               augment=False,\n",
    "                                               eval_augment=False,\n",
    "                                               atlas=atlas,\n",
    "                                               mask=mask,\n",
    "                                               )\n",
    "\n",
    "    running_metric = np.zeros(41)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    running_dice = 0.0\n",
    "    running_hausdorf = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_sens = 0.0\n",
    "    running_spec = 0.0\n",
    "    \n",
    "    running_meanl = 0.0\n",
    "    running_maxl = 0.0\n",
    "    running_minl = 0.0\n",
    "    phase=\"test\"\n",
    "    \n",
    "    mouses_df = pd.DataFrame()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders[phase]):\n",
    "            print(i, end='\\r')\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                rtype = registration_type.lower()\n",
    "                if rtype == 'affine' or rtype == 'local':\n",
    "                    ddf, pred_image, pred_label, _ = model(data)\n",
    "                elif rtype == 'deformable':\n",
    "                    affine_ddf, ddf, pred_image, pred_label, affine_image, affine_label = model(data)\n",
    "\n",
    "                pred_image = pred_image.to(device, non_blocking=True)\n",
    "                pred_label = pred_label.to(device, non_blocking=True)\n",
    "                pred_mask = AsDiscrete(threshold=0.5)(pred_label)\n",
    "                pred_mask_np = pred_mask.cpu().numpy().squeeze()\n",
    "\n",
    "                fixed_image = data['fixed_image'].to(device, non_blocking=True)\n",
    "                fixed_label = data['fixed_label'].to(device, non_blocking=True)\n",
    "                fixed_mask = AsDiscrete(threshold=0.5)(fixed_label)\n",
    "                fixed_mask_np = fixed_mask.cpu().numpy().squeeze()\n",
    "                \n",
    "                fixed_regions = data['fixed_regions'].to(device, non_blocking=True)\n",
    "                fixed_regions_np = fixed_regions.cpu().detach().numpy().squeeze()\n",
    "                moving_regions = data['moving_regions'].to(device, dtype=torch.float, non_blocking=True)\n",
    "                pred_regions = model.warp_nearest(moving_regions, ddf)\n",
    "                pred_regions_np = pred_regions.cpu().detach().numpy().squeeze()\n",
    "                \n",
    "                labelwarped = nib.Nifti1Image(pred_regions_np, atlas_affine, atlas_header)\n",
    "                outname_label = \"output/Neatin/neatin-1.1-continue/Label_A\" + str(i) + \".nii.gz\"\n",
    "                nib.save(labelwarped, outname_label)\n",
    "        \n",
    "                weights = [1, 0, 1] # to compare loss between methods\n",
    "                img_loss, lbl_loss, ddf_loss = get_deformable_registration_loss_from_weights(pred_image, pred_label,\n",
    "                                                                                                 fixed_image, fixed_label,\n",
    "                                                                                                 ddf, weights)\n",
    "                loss = img_loss + lbl_loss + ddf_loss\n",
    "                \n",
    "                ##################################\n",
    "                metric = evaluate(fixed_regions_np, pred_regions_np, metric=\"DSC\", multi_class=True, n_classes=41)               \n",
    "                \n",
    "                dice = evaluate(fixed_mask_np, pred_mask_np, metric=\"DSC\")   \n",
    "                hausdorf = evaluate(fixed_mask_np, pred_mask_np, metric=\"AHD\")  \n",
    "                iou = evaluate(fixed_mask_np, pred_mask_np, metric=\"IoU\")    \n",
    "                sens = evaluate(fixed_mask_np, pred_mask_np, metric=\"SENS\")\n",
    "                spec = evaluate(fixed_mask_np, pred_mask_np, metric=\"SPEC\")\n",
    "                \n",
    "                ##################################\n",
    "            \n",
    "            \n",
    "            running_metric += metric\n",
    "            \n",
    "            running_loss += loss.item() * fixed_image.size(0)\n",
    "            \n",
    "            running_dice += dice.item() * fixed_image.size(0)\n",
    "            running_hausdorf += hausdorf.item() * fixed_image.size(0)\n",
    "            running_iou  += iou.item() * fixed_image.size(0)\n",
    "            running_sens += sens.item() * fixed_image.size(0)\n",
    "            running_spec += spec.item() * fixed_image.size(0)\n",
    "\n",
    "            row = {\n",
    "                    'mouse': data['moving_image_meta_dict']['filename_or_obj'][0].split('/')[-1],\n",
    "                    'dsc_'+str(names[z]): dice,\n",
    "                    'ahd_'+str(names[z]): hausdorf,\n",
    "                    'iou_'+str(names[z]): iou,\n",
    "                    'sens_'+str(names[z]): sens,\n",
    "                    'spec_'+str(names[z]): spec,                \n",
    "            }\n",
    "            mouse_df = pd.DataFrame(data=row, index=[0])\n",
    "            mouses_df = pd.concat([mouses_df, mouse_df], ignore_index=True)\n",
    "\n",
    "\n",
    "    sizelol = 9  \n",
    "    for i in range(len(running_metric)):\n",
    "        running_metric[i] = running_metric[i] / sizelol\n",
    "    print(running_metric)\n",
    "    print(np.mean(running_metric))\n",
    "    running_loss /= sizelol\n",
    "    running_dice /= sizelol\n",
    "    running_hausdorf /= sizelol\n",
    "    running_iou /= sizelol\n",
    "    running_sens /= sizelol\n",
    "    running_spec /= sizelol\n",
    "    print(names[z])\n",
    "    print(\n",
    "        \"Loss: loss: {:.4f}\".format(\n",
    "            running_loss, \n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Labels: Dice: {:.4f} / Haussdorf: {:.4f} / IoU: {:.4f} / Sens: {:.4f} / Spec: {:.4f}\".format(\n",
    "            running_dice, running_hausdorf, running_iou, running_sens, running_spec\n",
    "        )\n",
    "    )\n",
    "    #print(mouses_df)\n",
    "    #mouses_df.to_csv(\"models/\" + modelname.split('/')[-1].split('.pth')[0] + '.csv', index=False)\n",
    "    print('-'*20)    \n",
    "    z += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa603b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mask = os.path.join(\"dataset2\", \"Atlas\", \"Identity_Neatin_Mask_A9.nii.gz\")\n",
    "template_mask = torch.from_numpy(nib.load(template_mask).get_fdata().reshape(1,128,128,128))\n",
    "template_mask = AsDiscrete(threshold=0.5)(template_mask)\n",
    "template_mask = template_mask.cpu().numpy().squeeze()\n",
    "\n",
    "template_labels = os.path.join(\"dataset2\", \"Atlas\", \"Identity_Neatin_Label_A9.nii.gz\")\n",
    "template_labels = nib.load(template_labels).get_fdata().squeeze()\n",
    "\n",
    "original_masks = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Mask_Resample_Identity\", \"*.nii.gz\")))\n",
    "original_labels = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Label_Resample_Identity\", \"*.nii.gz\")))\n",
    "affine_masks   = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Mask_Resample_Identity_Affine\", \"*.nii.gz\")))\n",
    "affine_labels = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Label_Resample_Identity_Affine\", \"*.nii.gz\")))\n",
    "ants_masks   = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Mask_Resample_Identity_Affine_Deformable\", \"*.nii.gz\")))\n",
    "ants_labels = sorted(glob(os.path.join(\"dataset2\", \"Neatin\", \"Label_Resample_Identity_Affine_Deformable\", \"*.nii.gz\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a99cdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No registration:\n",
      "[0.9962349  0.87878197 0.72694881 0.92326183 0.53373324 0.77756274\n",
      " 0.61172233 0.91490087 0.83510436 0.84315548 0.54773777 0.86936324\n",
      " 0.77427977 0.73019434 0.89348308 0.8617775  0.84263668 0.91405621\n",
      " 0.90206021 0.90736144 0.50032562 0.86562254 1.         0.91422581\n",
      " 0.5147797  0.75474318 0.50137138 0.90842942 0.83656034 0.81963978\n",
      " 1.         0.86953462 0.76898843 0.66215499 0.87319535 0.89036901\n",
      " 0.83584773 1.         0.89232392 0.898246   0.4410209 ]\n",
      "0.8056520847810733\n",
      "0.9519918553580354\n",
      "25.312776468601115\n",
      "0.9085492909334789\n",
      "0.9336248444884715\n",
      "0.9976215063662559\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dices = np.zeros(41)\n",
    "dice = 0\n",
    "hausdorf = 0\n",
    "iou = 0\n",
    "sens = 0\n",
    "spec = 0\n",
    "for i in range(len(original_masks)):\n",
    "    mask = torch.from_numpy(nib.load(original_masks[i]).get_fdata().reshape(1,128,128,128))\n",
    "    mask = AsDiscrete(threshold=0.5)(mask)\n",
    "    mask = mask.cpu().numpy().squeeze()\n",
    "    \n",
    "    labels = nib.load(original_labels[i]).get_fdata().squeeze()  \n",
    "    \n",
    "    dices += evaluate(template_labels, labels, metric=\"DSC\", multi_class=True, n_classes=41)  \n",
    "    \n",
    "    dice += evaluate(template_mask, mask, metric=\"DSC\") \n",
    "    hausdorf += evaluate(template_mask, mask, metric=\"AHD\")  \n",
    "    iou += evaluate(template_mask, mask, metric=\"IoU\")    \n",
    "    sens += evaluate(template_mask, mask, metric=\"SENS\")\n",
    "    spec += evaluate(template_mask, mask, metric=\"SPEC\")\n",
    "\n",
    "for i in range(len(dices)):\n",
    "    dices[i] = dices[i] / len(original_masks)\n",
    "dice /= len(original_masks)\n",
    "hausdorf /= len(original_masks)\n",
    "iou /= len(original_masks)\n",
    "sens /= len(original_masks)\n",
    "spec /= len(original_masks)\n",
    "\n",
    "print('No registration:')\n",
    "print(dices)\n",
    "print(np.mean(dices))\n",
    "print(dice)\n",
    "print(hausdorf)\n",
    "print(iou)\n",
    "print(sens)\n",
    "print(spec)\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9450b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine:\n",
      "[0.99725976 0.85468886 0.61163671 0.87524648 0.50411536 0.75864602\n",
      " 0.59698906 0.90196798 0.90831266 0.82572163 0.60204873 0.86189295\n",
      " 0.80367353 0.70932333 0.88813969 0.80123591 0.82939611 0.91673686\n",
      " 0.79205266 0.84668662 0.58398994 0.86505483 1.         0.80736001\n",
      " 0.40238604 0.64291276 0.59338206 0.89309892 0.90813504 0.81644566\n",
      " 1.         0.84251292 0.82479673 0.66216738 0.87832631 0.80904969\n",
      " 0.80931045 1.         0.80428086 0.82054416 0.53242658]\n",
      "0.7898036886361889\n",
      "0.965758134584607\n",
      "23.44314440785517\n",
      "0.933808066289877\n",
      "0.9617893581751535\n",
      "0.9974108623151634\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dices = np.zeros(41)\n",
    "dice = 0\n",
    "hausdorf = 0\n",
    "iou = 0\n",
    "sens = 0\n",
    "spec = 0\n",
    "for i in range(len(affine_masks)):\n",
    "    mask = torch.from_numpy(nib.load(affine_masks[i]).get_fdata().reshape(1,128,128,128))\n",
    "    mask = AsDiscrete(threshold=0.5)(mask)\n",
    "    mask = mask.cpu().numpy().squeeze()\n",
    "    \n",
    "    labels = nib.load(affine_labels[i]).get_fdata().squeeze()  \n",
    "    \n",
    "    dices += evaluate(template_labels, labels, metric=\"DSC\", multi_class=True, n_classes=41)  \n",
    "    \n",
    "    dice += evaluate(template_mask, mask, metric=\"DSC\")  \n",
    "    hausdorf += evaluate(template_mask, mask, metric=\"AHD\")  \n",
    "    iou += evaluate(template_mask, mask, metric=\"IoU\")    \n",
    "    sens += evaluate(template_mask, mask, metric=\"SENS\")\n",
    "    spec += evaluate(template_mask, mask, metric=\"SPEC\")\n",
    "for i in range(len(dices)):\n",
    "    dices[i] = dices[i] / len(original_masks)\n",
    "dice /= len(affine_masks)\n",
    "hausdorf /= len(affine_masks)\n",
    "iou /= len(affine_masks)\n",
    "sens /= len(affine_masks)\n",
    "spec /= len(affine_masks)\n",
    "\n",
    "print('Affine:')\n",
    "print(dices)\n",
    "print(np.mean(dices))\n",
    "print(dice)\n",
    "print(hausdorf)\n",
    "print(iou)\n",
    "print(sens)\n",
    "print(spec)\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc176fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyN:\n",
      "[0.99693309 0.84464335 0.56905685 0.83846545 0.46248764 0.71252112\n",
      " 0.58013421 0.89486696 0.90598678 0.81734694 0.58328378 0.84370097\n",
      " 0.78335958 0.65412979 0.8766218  0.76943282 0.84501271 0.89960425\n",
      " 0.76613274 0.81764587 0.56158182 0.83061914 1.         0.76834595\n",
      " 0.41988586 0.55867927 0.49024419 0.87658156 0.89362757 0.80950242\n",
      " 1.         0.81219093 0.81165326 0.66109051 0.86227324 0.7150862\n",
      " 0.83129874 1.         0.76992943 0.81096145 0.51078193]\n",
      "0.7672121994997342\n",
      "0.9614102092945284\n",
      "23.762033440650765\n",
      "0.9257737868092324\n",
      "0.9742582975615126\n",
      "0.9954546351849349\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dices = np.zeros(41)\n",
    "dice = 0\n",
    "hausdorf = 0\n",
    "iou = 0\n",
    "sens = 0\n",
    "spec = 0\n",
    "for i in range(len(ants_masks)):\n",
    "    mask = torch.from_numpy(nib.load(ants_masks[i]).get_fdata().reshape(1,128,128,128))\n",
    "    mask = AsDiscrete(threshold=0.5)(mask)\n",
    "    mask = mask.cpu().numpy().squeeze()\n",
    "    \n",
    "    labels = nib.load(ants_labels[i]).get_fdata().squeeze()  \n",
    "    \n",
    "    dices += evaluate(template_labels, labels, metric=\"DSC\", multi_class=True, n_classes=41)  \n",
    "    \n",
    "    dice += evaluate(template_mask, mask, metric=\"DSC\")   \n",
    "    hausdorf += evaluate(template_mask, mask, metric=\"AHD\")  \n",
    "    iou += evaluate(template_mask, mask, metric=\"IoU\")    \n",
    "    sens += evaluate(template_mask, mask, metric=\"SENS\")\n",
    "    spec += evaluate(template_mask, mask, metric=\"SPEC\")\n",
    "    \n",
    "for i in range(len(dices)):\n",
    "    dices[i] = dices[i] / len(original_masks)\n",
    "dice /= len(ants_masks)\n",
    "hausdorf /= len(ants_masks)\n",
    "iou /= len(ants_masks)\n",
    "sens /= len(ants_masks)\n",
    "spec /= len(ants_masks)\n",
    "\n",
    "print('SyN:')\n",
    "print(dices)\n",
    "print(np.mean(dices))\n",
    "print(dice)\n",
    "print(hausdorf)\n",
    "print(iou)\n",
    "print(sens)\n",
    "print(spec)\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa65e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
